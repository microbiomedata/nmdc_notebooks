{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proteomic Data Aggregation and Visualization\n",
    "\n",
    "\n",
    "This notebook demonstrates aggregation of proteomic data via the National Microbiome Data Collaborative (NMDC)'s [Runtime API](https://api.microbiomedata.org/docs). It highlights how the NMDC's schema can be used to overcome some of the numerous challenges associated with this type of aggregation. Please note that this notebook is intended for individuals with experience performing mass spectrometry based proteomic analyses and that various parameter and processing choices were made for this example use case. They are not broadly applicable and should be adjusted as needed. \n",
    "\n",
    "\n",
    "Notebook Steps:\n",
    "\n",
    "1) Assess background information and collect datasets for an example study of riverbed sediment along the Columbia River\n",
    "\n",
    "2) Apply a spectral probability filter across the data that optimizes the number of identifications for an FDR of 0.05\n",
    "\n",
    "3) Collapse to unique peptides and normalize quantification\n",
    "\n",
    "4) Extract functional gene annotations for proteins\n",
    "\n",
    "5) Generate annotation and protein mappings for peptides using \"Razor\" strategy\n",
    "\n",
    "6) Perform protein rollup using the \"Razor\" results and summarize into an aggregated table of relative protein abundance\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries and python scripts containing functions necessary to run this notebook. 'aggregation_functions.py' (also in this folder) includes spectral probability filtering and protein mapping functions. 'nmdc_api.py' (located in NOM_visualization/python) includes functions for API traversal of the collections endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Setup \n",
    "# Add renv project library to R environment variable libPaths()\n",
    ".libPaths(c(.libPaths(), \"../../renv/library/*/R-*/*\"))\n",
    "\n",
    "# Load required packages\n",
    "suppressPackageStartupMessages({\n",
    "  library(dplyr, warn.conflicts = FALSE)\n",
    "  library(tidyr, warn.conflicts = FALSE)\n",
    "  library(stringr, warn.conflicts = FALSE)\n",
    "  library(readr, warn.conflicts = FALSE)\n",
    "  library(ggplot2, warn.conflicts = FALSE)\n",
    "  library(jsonlite, warn.conflicts = FALSE)\n",
    "  library(janitor, warn.conflicts = FALSE)\n",
    "  library(grid, warn.conflicts = FALSE)\n",
    "  })\n",
    "\n",
    "# Load NMDC API functions from this repo\n",
    "if(Sys.getenv(\"COLAB_BACKEND_VERSION\") == \"\") {\n",
    "  source(\"../../utility_functions.R\")\n",
    "  # import aggregation functions script\n",
    "}\n",
    "\n",
    "if(Sys.getenv(\"COLAB_BACKEND_VERSION\") != \"\") {\n",
    "  source(\"http://raw.githubusercontent.com/microbiomedata/nmdc_notebooks/refs/heads/main/utility_functions.R\")\n",
    "  # import aggregation functiosn script\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Assess background information and collect data for an example study of riverbed sediment along the Columbia River"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the example study on the [NMDC data portal](https://data.microbiomedata.org/details/study/nmdc:sty-11-aygzgv51). Use the study `id` embedded in the url (nmdc:sty-11-aygzgv51) to collect all related data objects via the [NMDC Runtime API](https://api.microbiomedata.org/docs) and reformat the json output into a pandas dataframe. These data objects reference both input files (i.e. raw, gff) and output files (i.e. metaproteomic results) to the NMDC workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "data_objects <- get_data_objects_for_study(\"nmdc:sty-11-aygzgv51\") %>%\n",
    "  # Remove unnecessary columns for simpler dataframe\n",
    "  select(id, name, file_size_bytes, data_object_type, md5_checksum, url, biosample_id, in_manifest) %>%\n",
    "  # Flatten in_manifest\n",
    "  mutate(in_manifest = as.character(in_manifest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset the data objects to 'Unfiltered Metaproteomic Results'. These files contain the proteomic workflow outputs that will be used for proteomic aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "proteomic_output_df <- data_objects %>%\n",
    "  filter(data_object_type == \"Unfiltered Metaproteomics Results\") %>%\n",
    "  dplyr::rename(processed_dobj_id = \"id\")\n",
    "\n",
    "head(proteomic_output_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are various requirements that enable mass spectrometry runs to be aggregated and analyzed together. For example, runs need to be performed in succession, on the same instrument. The NMDC schema can make it easier to find these proteomic results by linking them via a slot called `in_manifest`.\n",
    "\n",
    "Look at the `in_manifest` id on these proteomic outputs to confirm that all runs are in the same manifest record, and pull that record. If that manifest record's `manifest_category` value is 'instrument_run', then it confirms that these are LC-MS/MS runs that were performed in succession on the same instrument. Proteomic outputs from different manifest records should not be aggregated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Display manifest IDs for the records in proteomic_output_df\n",
    "manifest_id <- unique(proteomic_output_df$in_manifest)\n",
    "\n",
    "# In this case there is only one, print manifest information\n",
    "manifest <- get_results_by_id(collection = \"manifest_set\", \n",
    "                              match_id_field = \"id\", \n",
    "                              id_list = manifest_id, \n",
    "                              fields = \"\")\n",
    "manifest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at an example of the information in 'Unfiltered Metaproteomics Results', which contains peptide identification and relative abundance information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "paste(\"Reading file from\", proteomic_output_df$url[1])\n",
    "\n",
    "head(read_tsv(proteomic_output_df$url[1], show_col_types = FALSE, progress = FALSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract information from all 33 proteomic results via the function iterate_file_extract() in agg_func, and put them into a single dataframe, where each scan in each dataset has the unique identifier `SpecID`. Clean prefix and suffix off of each peptide sequence. Since this data was processed using a target-decoy approach, determine the type of protein being matched to each peptide: contaminant, reverse (false positive match to the reversed amino acid sequence of a protein), or forward (match to the true, forward amino acid sequence of a protein). The presence of forward and reverse matches enables FDR estimation in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Define functions\n",
    "\n",
    "gff_extract_features <- function(url) {\n",
    "  \n",
    "  withCallingHandlers(\n",
    "    expr = {\n",
    "      \n",
    "      tsv_df <- suppressWarnings(read_tsv(url, col_names = FALSE, progress = FALSE, show_col_types = FALSE))\n",
    "      \n",
    "      colnames(tsv_df) <- c(\"seqname\", \"source\", \"feature\", \"start\", \"end\", \"score\", \"strand\", \"frame\", \"attribute\") \n",
    "      # See https://www.ensembl.org/info/website/upload/gff.html for GFF format specification\n",
    "      \n",
    "      # Break \"attribute\" column by separator\n",
    "      tsv_df <- strsplit(tsv_df$attribute, split = \";\") %>%\n",
    "        lapply(strsplit, split = \"=\") %>%\n",
    "        lapply(function (x) { \n",
    "          do.call(rbind, x) %>%\n",
    "            t() %>%\n",
    "            data.frame() %>%\n",
    "            row_to_names(row_number = 1) }) %>%\n",
    "        bind_rows() %>%\n",
    "        distinct()\n",
    "    },\n",
    "    error = function(e) print(paste(\"Error while reading GFF from\", url, \":\", e))\n",
    "  )\n",
    "  return(tsv_df)\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "iterate_file_extract <- function(input_df, identifier_col, url_col, \n",
    "                                 extract_cols, file_type, \n",
    "                                 filter_col = NA, filter_values = NA) {\n",
    "  \n",
    "  output <- vector(mode = \"list\", length = nrow(input_df))\n",
    "\n",
    "  for (row in 1:nrow(input_df)) {\n",
    "    \n",
    "    # Extract url and id for readability\n",
    "    file_url <- input_df[[url_col]][row]\n",
    "    identifier <- input_df[[identifier_col]][row]\n",
    "    \n",
    "    tryCatch(\n",
    "      expr = {\n",
    "        if(file_type == \"tsv\") {\n",
    "          df <- read_tsv(file_url, show_col_types = FALSE, progress = FALSE)\n",
    "          }\n",
    "        if (file_type == \"gff\") {\n",
    "          df <- gff_extract_features(file_url)\n",
    "        }\n",
    "      },\n",
    "      error = function(e) print(paste(\"An error occurred fetching data from\", identifier, \":\", e))\n",
    "    )\n",
    "    \n",
    "    # Check that the subsetted df will have unique rows, otherwise break\n",
    "    if(nrow(df) != nrow(distinct(df[extract_cols]))) {\n",
    "      print(paste(\"Selected columns result in non-unique rows for \", identifier, \". Data will not be included in output.\"))\n",
    "      break\n",
    "    }\n",
    "    \n",
    "    # Subset data frame to desired columns\n",
    "    df <- df[extract_cols]\n",
    "    \n",
    "    # Filter if specified\n",
    "    if (!is.na(filter_col) & all(is.na(filter_values))) {\n",
    "      df <- filter(df, {{filter_col}} %in% filter_values)\n",
    "    }\n",
    "    \n",
    "    # Add identifier column\n",
    "    df <- mutate(df, id = identifier)\n",
    "    \n",
    "    # Append to list\n",
    "    output[[row]] <- df\n",
    "  }\n",
    "  return(bind_rows(output))\n",
    "}\n",
    "\n",
    "trim_peptide_sequence <- function(s) {\n",
    "  str_match(s, \"\\\\.([A-Z\\\\\\\\*@#]+)\\\\.\")[, 2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "unfiltered_results <- iterate_file_extract(input_df = proteomic_output_df,\n",
    "                                           identifier_col = \"processed_dobj_id\",\n",
    "                                           url_col = \"url\", \n",
    "                                           extract_cols = c(\"Charge\", \"Scan\", \"Peptide\", \"Protein\", \"MSGFDB_SpecEValue\", \"StatMomentsArea\"),\n",
    "                                           file_type = \"tsv\") %>%\n",
    "\n",
    "\n",
    "# #create identifier for each scan in each dataset\n",
    "# unfilt_res[\"SpecID\"] = unfilt_res.apply(lambda row: str(row[\"id_col\"]) + \"_\" + str(row[\"Scan\"]), axis=1)\n",
    "\n",
    "\n",
    "  mutate(SpecID = paste(id, Scan, sep = \"_\")) %>%\n",
    "\n",
    "# #clean off the prefix and suffix from the sequence but keep any mods\n",
    "# unfilt_res[\"Peptide Sequence with Mods\"] = unfilt_res[\"Peptide\"].apply(agg_func.sequence_noprefsuff)\n",
    "# del unfilt_res['Peptide']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  mutate(Peptide_Sequence_with_Mods = trim_peptide_sequence(Peptide)) %>%\n",
    "\n",
    "\n",
    "\n",
    "# #determine protein type (contaminant, reverse, forward)\n",
    "# unfilt_res[\"Protein_Type\"] = unfilt_res[\"Protein\"].apply(agg_func.findproteinname)\n",
    "\n",
    "  mutate(Protein_Type = case_when(\n",
    "    str_detect(Protein, \"Contaminant\") ~ \"None\",\n",
    "    str_detect(Protein, \"^XXX_\") ~ \"Reversed\",\n",
    "    TRUE ~ \"Forward\"))\n",
    "\n",
    "# unfilt_res\n",
    "\n",
    "head(unfiltered_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Apply a spectral probability filter across the data that optimizes the number of identifications for an FDR of 0.05\n",
    "\n",
    "A challenge associated with aggregating mass spectrometry data is that there are always false identifications, which can be mitigated by imposing a spectral probability filter on the data being analyzed. The same spectral probability filter needs to be applied across datasets when they are being compared. The filter value itself is chosen by weighing the number of 'true' identifications retained with the proximity of the data to a chosen false discovery rate (FDR) (usually 0.05 or 0.01). NMDC's metaproteomic workflow provides 'true' and 'false' identifications for FDR estimation in the 'Unfiltered Metaproteomic Result' files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe of peptide identifications (ignoring protein mapping). Filter identifications to the peptide sequence with the smallest SpecEValue for each SpecID, so there is a single, highest probability identification for each scan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "edata <- distinct(unfiltered_results, SpecID, Peptide_Sequence_with_Mods, MSGFDB_SpecEValue, Protein_Type, StatMomentsArea, .keep_all = TRUE)\n",
    "\n",
    "\n",
    "\n",
    "#for each SpecID, select the peptide spectrum match with the smallest MSGFDB_SpecEValue (.idxmin() takes the first entry when there's multiple matches)\n",
    "# idx = edata.groupby(['SpecID'])['MSGFDB_SpecEValue'].idxmin()\n",
    "# edata = edata.loc[idx].reset_index(drop=True)\n",
    "# del idx\n",
    "\n",
    "edata <- edata %>% \n",
    "  group_by(SpecID) %>% \n",
    "  slice_min(MSGFDB_SpecEValue, with_ties = FALSE, n = 1) %>% \n",
    "  ungroup()\n",
    "\n",
    "\n",
    "\n",
    "# display(edata)\n",
    "\n",
    "head(edata)\n",
    "\n",
    "# assert len(edata['SpecID'].unique())==edata.shape[0], \"still more than one identification per scan\"\n",
    "\n",
    "stopifnot(\"Still more than one identification per scan\" = length(unique(edata$SpecID)) == length(edata$SpecID))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create separate dataframes of forward and reverse peptide spectrum matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "forward_peptides <- filter(edata, Protein_Type == \"Forward\") %>% select(-Protein_Type)\n",
    "\n",
    "head(forward_peptides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "reversed_peptides <- filter(edata, Protein_Type == \"Reversed\") %>% select(-Protein_Type)\n",
    "\n",
    "head(reversed_peptides)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the function optimize_specFilt() in agg_func to find a log10 spectral probability filter that weighs the number of forward peptides retained with the proximity of the dataset to a 0.05 spectral FDR. Visualize the impact of the spectral probability filter by plotting the number of forward and reverse peptides retained. \n",
    "\n",
    "The main plot below is a histogram of forward and reverse peptides across all spectral probability values. The inset within this plot depicts a subset of the smallest spectral probabililty values, with the red bar before the dashed line representing the estimated number of false identifications that will be included in this analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#initial guess at a log10 spectral probability filter value\n",
    "initial_specprob_filter = -15\n",
    "\n",
    "\n",
    "spec_filt_value <- function(specprob, forward_peptides, reversed_peptides) {\n",
    "\n",
    "  df_r <- filter(reversed_peptides, MSGFDB_SpecEValue < 10 ^ specprob)\n",
    "  df_f <- filter(forward_peptides, MSGFDB_SpecEValue < 10 ^ specprob)\n",
    "\n",
    "  f_spec <- length(unique(df_f$SpecID))\n",
    "  r_spec <- length(unique(df_r$SpecID))\n",
    "  \n",
    "  fdr_spec <- ifelse(f_spec == 0 & r_spec == 0,\n",
    "                     1,\n",
    "                     (2 * r_spec) / (f_spec + r_spec))\n",
    "    \n",
    "  filter_value <- 1 / (0.050001 - fdr_spec) * (-f_spec)\n",
    "  \n",
    "  return(filter_value)\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "optimize_spec_filt <- function(initial_specprob_filter, forward_peptides, reversed_peptides) {\n",
    "\n",
    " result <- optim(fn = spec_filt_value, par = initial_specprob_filter, \n",
    "          forward_peptides = forward_peptides, reversed_peptides = reversed_peptides,\n",
    "           method = \"Brent\", lower = -100, upper = 100)\n",
    " \n",
    " # Brent method for optim() function always returns 0 (success) for convergence\n",
    " \n",
    "  tryCatch(\n",
    "    expr = {\n",
    "      result <- optim(fn = spec_filt_value, par = initial_specprob_filter, \n",
    "                      reversed_peptides = reversed_peptides, forward_peptides = forward_peptides,\n",
    "                      method = \"Brent\", lower = -100, upper = 100)\n",
    "      },\n",
    "    error = function(e) message(paste(\"Error in optimization:\", e)),\n",
    "    warning = function(w) message(paste(\"Warning in optimization:\", w))\n",
    "  )\n",
    "}\n",
    "\n",
    "optimized_filter <- optimize_spec_filt(initial_specprob_filter, forward_peptides, reversed_peptides)$par\n",
    "\n",
    "\n",
    "peps_for_plot <- bind_rows(forward_peptides, reversed_peptides, .id = \"direction\") %>%\n",
    "  mutate(direction = case_when(direction == 1 ~ \"forward\", direction == 2 ~ \"reverse\"),\n",
    "         direction = factor(direction))\n",
    "\n",
    "main_plot <- ggplot(peps_for_plot) +\n",
    "  geom_histogram(aes(x = MSGFDB_SpecEValue, fill = direction), bins = 50, alpha = 0.5, position = \"identity\") + \n",
    "  geom_vline(xintercept = 10 ^ optimized_filter) +\n",
    "  scale_fill_manual(values = c(\"forward\" = \"seagreen\", \"reverse\" = \"orangered\")) +\n",
    "  ylab(\"Number of peptide-spectrum matches\") +\n",
    "  ggtitle(\"Impact of spectral probability filter\")\n",
    "\n",
    "zoom_plot <- peps_for_plot %>%\n",
    "  # subset data - zoom in \n",
    "  filter(MSGFDB_SpecEValue < 2e-9) %>%\n",
    "  ggplot() +\n",
    "    geom_histogram(aes(x = MSGFDB_SpecEValue, fill = direction), bins = 30, alpha = 0.5, position = \"identity\") + \n",
    "    geom_vline(xintercept = 10 ^ optimized_filter) +\n",
    "    scale_fill_manual(values = c(\"forward\" = \"seagreen\", \"reverse\" = \"orangered\")) +\n",
    "    theme(legend.position = \"none\", axis.title.x = element_blank(), axis.title.y = element_blank())\n",
    "    \n",
    "vp <- viewport(width = 0.4, height = 0.45, x = 0.6, y = 0.65)\n",
    "\n",
    "main_plot\n",
    "print(zoom_plot, vp = vp)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the filter to the dataset and recalculate peptide and spectral FDR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "forward_peptides <- filter(forward_peptides, MSGFDB_SpecEValue < 10 ^ optimized_filter)\n",
    "\n",
    "# reversed_peptides = reversed_peptides[\n",
    "#     (reversed_peptides[\"MSGFDB_SpecEValue\"] < 10 ** optimization.x[0])\n",
    "# ].copy()\n",
    "\n",
    "reversed_peptides <- filter(reversed_peptides, MSGFDB_SpecEValue < 10 ^ optimized_filter)\n",
    "\n",
    "\n",
    "# Calculate FDR\n",
    "# f_spec = (forward_peptides[\"SpecID\"].unique().size)\n",
    "# r_spec = reversed_peptides[\"SpecID\"].unique().size\n",
    "\n",
    "f_spec <- length(unique(forward_peptides$SpecID))\n",
    "r_spec <- length(unique(reversed_peptides$SpecID))\n",
    "\n",
    "\n",
    "# if (f_spec == 0) & (r_spec == 0):\n",
    "#     fdr_spec = 1\n",
    "# else:\n",
    "#     fdr_spec = (2*r_spec) / (f_spec + r_spec)\n",
    "\n",
    "fdr_spec <- ifelse(f_spec == 0 & r_spec == 0,\n",
    "                   1,\n",
    "                   (2 * r_spec) / (f_spec + r_spec))\n",
    "\n",
    "# f_pep = forward_peptides[\"Peptide Sequence with Mods\"].unique().size\n",
    "# r_pep = reversed_peptides[\"Peptide Sequence with Mods\"].unique().size\n",
    "\n",
    "f_pep <- length(unique(forward_peptides$Peptide_Sequence_with_Mods))\n",
    "r_pep <- length(unique(reversed_peptides$Peptide_Sequence_with_Mods))\n",
    "\n",
    "\n",
    "# if (f_pep == 0) & (r_pep == 0):\n",
    "#     fdr_pep = 1\n",
    "# else:\n",
    "#     fdr_pep = (r_pep) / (f_pep + r_pep)\n",
    "\n",
    "\n",
    "fdr_pep <- ifelse(f_pep == 0 & r_pep == 0,\n",
    "                  1,\n",
    "                  r_pep / (f_pep + r_pep))\n",
    "\n",
    "# print(\"Spectral FDR:\",fdr_spec,\"\\nPeptide FDR:\",fdr_pep)\n",
    "\n",
    "\n",
    "paste(\"Spectral FDR:\", fdr_spec)\n",
    "paste(\"Peptide FDR:\", fdr_pep)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Collapse to unique peptides and normalize their relative abundance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point in analysis the data has been filtered to only high probability peptide identifications, but more than one scan within a dataset can have the same peptide identification. This can be due to the peptide eluting into the mass spectrometer over the course of multiple scans or a peptide eluting as multiple charge states. Sum the relative abundance for peptide sequences detected more than once in a dataset, leaving a total relative abundance value for each peptide in each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "forward_peptides <- forward_peptides %>%\n",
    "  dplyr::rename(processed_dobj_id = id) %>%\n",
    "  select(-c(SpecID, MSGFDB_SpecEValue)) %>%\n",
    "  group_by(processed_dobj_id, Peptide_Sequence_with_Mods) %>%\n",
    "  mutate(StatMomentsArea = sum(StatMomentsArea)) %>% \n",
    "  ungroup() %>%\n",
    "  distinct(processed_dobj_id, Peptide_Sequence_with_Mods, StatMomentsArea)\n",
    "\n",
    "head(forward_peptides)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the untransformed and un-normalized relative abundances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "ggplot(forward_peptides) +\n",
    "  geom_boxplot(aes(x = processed_dobj_id, y = StatMomentsArea)) +\n",
    "  labs(x = \"Samples\", y = \"Relative Peptide Abundance (Not Normalized)\", title = \"Peptide relative abundances by sample\") +\n",
    "  theme(axis.text.x = element_blank())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply log2 transformation and median normalize peptide abundances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "forward_peptides <- forward_peptides %>%\n",
    "  mutate(StatMomentsAreaLog2 = log2(StatMomentsArea)) %>%\n",
    "  group_by(processed_dobj_id) %>%\n",
    "  mutate(group_medians = median(StatMomentsAreaLog2)) %>%\n",
    "  ungroup() %>%\n",
    "  distinct()\n",
    "\n",
    "\n",
    "# Calculate data wide median\n",
    "# all_data_median=forward_peptides['StatMomentsAreaLog2'].median()\n",
    "\n",
    "all_data_median <- median(forward_peptides$StatMomentsAreaLog2)\n",
    "\n",
    "# Subtract sample wise median from each value within its group\n",
    "# forward_peptides['StatMomentsAreaLog+Norm'] = forward_peptides.apply(\n",
    "#     lambda row: row['StatMomentsAreaLog2'] - group_medians[row['processed_DO_id']], axis=1\n",
    "# )\n",
    "\n",
    "#add back in a data wide median value to avoid negative abundances\n",
    "# forward_peptides['StatMomentsAreaLog+Norm'] = forward_peptides['StatMomentsAreaLog+Norm'] + all_data_median\n",
    "\n",
    "\n",
    "forward_peptides <- forward_peptides %>%\n",
    "  mutate(StatMomentsAreaLogNorm = StatMomentsAreaLog2 - group_medians + all_data_median)\n",
    "\n",
    "\n",
    "\n",
    "# transformed_abundances_fig, ax = plt.subplots(figsize=(8,6))\n",
    "# sns.boxplot(x='processed_DO_id',y='StatMomentsAreaLog+Norm',data=forward_peptides)\n",
    "# plt.xticks([])\n",
    "# plt.xlabel('sample')\n",
    "# plt.ylabel('Relative Peptide Abundance (Normalized)')\n",
    "# \n",
    "# del ax, group_medians, all_data_median, forward_peptides['StatMomentsArea'], forward_peptides['StatMomentsAreaLog2'], reversed_peptides\n",
    "\n",
    "\n",
    "ggplot(forward_peptides) +\n",
    "  geom_boxplot(aes(x = processed_dobj_id, y = StatMomentsAreaLogNorm)) +\n",
    "  labs(x = \"Samples\", y = \"Relative Peptide Abundance (Normalized)\", title = \"Peptide relative abundances by sample\") +\n",
    "  theme(axis.text.x = element_blank())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Extract functional gene annotations for proteins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect peptide to protein mapping information for the passing peptide sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "peptide_protein_mapping <- unfiltered_results %>%\n",
    "  filter(Peptide_Sequence_with_Mods %in% forward_peptides$Peptide_Sequence_with_Mods) %>%\n",
    "  distinct(Peptide_Sequence_with_Mods, Protein)\n",
    "\n",
    "peptide_protein_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annotation information for these proteins can be found in 'Functional Annotation GFF' files.\n",
    "\n",
    "Since the `data_objects` dataframe contains all objects associated with our study id, it also contains the relevant 'Functional Annotation GFF' files. Subset this dataframe to GFF files associated with the 33 biosample ids that have a proteomic output in `proteomic_output_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "annotation_input_df <- data_objects %>%\n",
    "  filter(data_object_type == \"Functional Annotation GFF\") %>%\n",
    "  filter(biosample_id %in% proteomic_output_df$biosample_id) %>%\n",
    "  distinct(biosample_id, id, data_object_type, url)\n",
    "\n",
    "# display(annotation_input_df)\n",
    "\n",
    "head(annotation_input_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview the 'Functional Annotation GFF' files and determine a subset of gene annotation information that should be pulled from all 33 files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "paste(\"Reading from\", annotation_input_df$url[2])\n",
    "\n",
    "head(gff_extract_features(annotation_input_df$url[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract information from all 33 annotation files (this takes a while to run) and merge with `razormapping` so there is a final table of peptide-protein-annotation mapping (`annotation_mapping`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "gene_mapping <- distinct(annotation_input_df, id, url)\n",
    "\n",
    "# genemapping = agg_func.iterate_file_extract(\n",
    "#     pd_df=genemapping,\\\n",
    "#     identifier_col='id',\\\n",
    "#     url_col='url',\\\n",
    "#     extract_cols=['ID','product','product_source'],\\\n",
    "#     filter_col = 'ID',\n",
    "#     filter_values = peptide_protein_mapping['Protein'].unique().tolist(),\n",
    "#     file_type='gff'\n",
    "# )\n",
    "\n",
    "\n",
    "gene_mapping <- iterate_file_extract(\n",
    "  input_df = gene_mapping,\n",
    "  identifier_col = \"id\",\n",
    "  url_col = \"url\",\n",
    "  extract_cols = c(\"ID\", \"product\", \"product_source\"),\n",
    "  filter_col = \"ID\",\n",
    "  filter_values = unique(peptide_protein_mapping$Protein),\n",
    "  file_type = \"gff\"\n",
    ")\n",
    "\n",
    "\n",
    "#merge with protein mapping information. drop columns ID (which is equivalent to Protein) and id_col (which is the dataset id, unnecessary here since peptide to protein information isn't dataset specific)\n",
    "# annotation_mapping = genemapping.merge(peptide_protein_mapping,left_on='ID',right_on='Protein').drop(['ID','id_col'],axis=1)\n",
    "\n",
    "annotation_mapping <- inner_join(gene_mapping, peptide_protein_mapping, by = join_by(ID == Protein)) %>%\n",
    "  distinct()\n",
    "\n",
    "annotation_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Generate annotation and protein mappings for peptides using \"Razor\" strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the razor protein, which is a method of limiting the assignment of degenerate peptides (i.e., peptides that map to more than one forward protein) to a most likely matched protein. 'Razor' references the principle Occam's razor, also known as the law of parsimony.\n",
    "\n",
    "The rules are as follows:\n",
    "- If a peptide is unique to a protein, then that protein is the razor\n",
    "- Else, if a peptide belongs to more than one protein, but one of those proteins has a unique peptide, then that protein is the razor\n",
    "- Else, if a peptide belongs to more than one protein and one of those proteins has the maximal number of peptides, then that protein is the razor\n",
    "- Else, if a peptide belongs to more than one protein and more than one of those proteins has the maximal number of peptides, then collapse the proteins and gene annotations into single strings\n",
    "- Else, if a peptide belongs to more than one protein and more than one of those proteins has a unique peptide, then the peptide is removed from analysis because its mapping is inconclusive\n",
    "\n",
    "Use `annotation_mapping` as the input to the function razorprotein() from the agg_func script. This will return protein and gene annotation information for each peptide, according to the above rules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Add counts for use in razor logic function\n",
    "# annotation_mapping has already been through distinct() so pairs (rows) are unique\n",
    "annotation_mapping <- annotation_mapping %>%\n",
    "  \n",
    "  dplyr::rename(Protein = ID) %>%\n",
    "  \n",
    "  # Count the number of proteins that each peptide maps to\n",
    "  group_by(Peptide_Sequence_with_Mods) %>%\n",
    "  mutate(prot_count = n()) %>%\n",
    "  ungroup() %>%\n",
    "  \n",
    "  # Count the number of REDUNDANT and UNIQUE peptides that each protein maps to\n",
    "  group_by(Protein) %>%\n",
    "  mutate(redundant_pep_count = sum(prot_count > 1),\n",
    "         unique_pep_count = sum(prot_count == 1)) %>%\n",
    "  ungroup()\n",
    "\n",
    "annotation_mapping\n",
    "\n",
    "\n",
    "get_razor_protein <- function(mapping_df) {\n",
    "    \n",
    "  # Make the mapping df into a bunch of named vectors for easier indexing\n",
    "  \n",
    "  # Names = peptides, values = number of proteins the peptide maps to\n",
    "  a <- distinct(mapping_df, Peptide_Sequence_with_Mods, prot_count)\n",
    "  prot_count_vec <- setNames(a$prot_count, a$Peptide_Sequence_with_Mods)\n",
    "  \n",
    "  # Names = peptides, values = proteins\n",
    "  pep_prot_vec <- setNames(mapping_df$Protein, nm = mapping_df$Peptide_Sequence_with_Mods)\n",
    "  \n",
    "  # Create vector of all peptides for readability\n",
    "  pep_vec <- a$Peptide_Sequence_with_Mods\n",
    "  rm(a)\n",
    "  \n",
    "\n",
    "  # Pre allocate results list\n",
    "  razor_result <- vector(mode = \"list\", length = length(pep_vec))\n",
    "  \n",
    "  # Iterate through peptides to choose a razor protein for each one\n",
    "  for (pep in 1:length(pep_vec)) {\n",
    "    \n",
    "    query_peptide <- pep_vec[pep]\n",
    "    \n",
    "    # If the peptide only maps to one protein, that is the razor protein\n",
    "    if (prot_count_vec[query_peptide] == 1) { razor_result[[pep]] <- pep_prot_vec[query_peptide] }\n",
    "    \n",
    "    # If the peptide maps to more than one protein and ...\n",
    "    else {\n",
    "      mapping_subset <- filter(mapping_df, Peptide_Sequence_with_Mods == query_peptide)\n",
    "      prots_with_unique_peptides <- sum(mapping_subset$unique_pep_count > 0)\n",
    "      \n",
    "      razor_result[[pep]] <- case_when(\n",
    "        \n",
    "        # ...there is only one potential protein with unique peptides, that is the razor protein\n",
    "        prots_with_unique_peptides == 1 ~ mapping_subset$Protein[which.max(mapping_subset$unique_pep_count)],\n",
    "        \n",
    "        # ...there is more than one potential protein with unique peptides, razor protein cannot be determined\n",
    "        prots_with_unique_peptides > 1  ~ \"indeterminate - discard\",\n",
    "        \n",
    "        # ...there are no potential proteins with unique peptides, \n",
    "        # and ONE potential protein has the most redundant peptides, that is the razor protein\n",
    "        # note: which.max returns the FIRST maximum index which in this case should be the only one\n",
    "        prots_with_unique_peptides == 0 & \n",
    "          sum(mapping_subset$redundant_pep_count == max(mapping_subset$redundant_pep_count)) == 1 ~ \n",
    "          mapping_subset$Protein[which.max(mapping_subset$redundant_pep_count)],\n",
    "        \n",
    "        # ...there are no potential proteins with unique peptides, \n",
    "        # and more than one potential protein has the most redundant peptides, those are the razor proteins\n",
    "        # note: which ( blah == max(blah) ) will return ALL of the maximum indices\n",
    "        prots_with_unique_peptides == 0 &\n",
    "          sum(mapping_subset$redundant_pep_count == max(mapping_subset$redundant_pep_count)) > 1 ~ \n",
    "          mapping_subset$Protein[which(mapping_subset$redundant_pep_count == max(mapping_subset$redundant_pep_count))],\n",
    "        \n",
    "        # there should be no cases not captured\n",
    "        TRUE ~ \"fix razor logic until you don't see this\"\n",
    "      )\n",
    "    }\n",
    "    razor_result[[pep]] <- data.frame(Peptide = query_peptide,\n",
    "                                      Razor_Protein = razor_result[[pep]], \n",
    "                                      row.names = NULL)\n",
    "  }\n",
    "  # Bind into one long dataframe\n",
    "  bind_rows(razor_result, .id = NULL) %>%\n",
    "    \n",
    "    # Discard indeterminate cases\n",
    "    filter(Razor_Protein != \"indeterminate - discard\") %>%\n",
    "    \n",
    "    # Add the protein annotations back in\n",
    "    left_join(select(mapping_df, Protein, product, product_source, Peptide_Sequence_with_Mods),\n",
    "              by = join_by(Razor_Protein == Protein, Peptide == Peptide_Sequence_with_Mods)) %>%\n",
    "    distinct()\n",
    "}\n",
    "\n",
    "razor_mapping_long <- get_razor_protein(annotation_mapping)\n",
    "\n",
    "razor_mapping_oneline <- razor_mapping_long %>%\n",
    "  group_by(Peptide) %>%\n",
    "  mutate(Razor_Protein  = paste(Razor_Protein, collapse = \", \"),\n",
    "         product        = paste(product, collapse = \", \"),\n",
    "         product_source = paste(product_source, collapse = \", \")) %>%\n",
    "  ungroup() %>%\n",
    "  distinct()\n",
    "\n",
    "razor_mapping_oneline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Perform protein rollup and summarize into a final aggregated table of relative protein abundance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine razor information with relative abundance values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "forward_peptides <- forward_peptides %>%\n",
    "  right_join(razor_mapping_oneline, by = join_by(Peptide_Sequence_with_Mods == Peptide)) %>%\n",
    "  distinct()\n",
    "\n",
    "forward_peptides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De-log the peptide abundances, sum the abundances for each razor protein and log transform the rolled up protein abundances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "protein_abundances <- forward_peptides %>%\n",
    "  mutate(StatMomentsAreaNorm = 2 ^ StatMomentsAreaLogNorm) %>%\n",
    "  group_by(processed_dobj_id, Razor_Protein) %>%\n",
    "  mutate(StatMomentsAreaNormSum = sum(StatMomentsAreaNorm)) %>%\n",
    "  ungroup() %>%\n",
    "  distinct(processed_dobj_id, product, product_source, Razor_Protein, StatMomentsAreaNormSum) %>%\n",
    "  mutate(StatMomentsAreaLogNormSum = log2(StatMomentsAreaNormSum)) %>%\n",
    "  select(-StatMomentsAreaNormSum)\n",
    "\n",
    "\n",
    "protein_abundances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final aggregated table of relative protein abundance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reformat these results into a proteomic table, where each row indicates a protein and each column indicates a sample/dataset. The values within are log transformed, median normalized relative abundance values. This table or the longform version above can be used in further proteomic analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "aggregated_proteomic_output <- protein_abundances %>%\n",
    "  select(processed_dobj_id, Razor_Protein, StatMomentsAreaLogNormSum) %>%\n",
    "  pivot_wider(names_from = \"processed_dobj_id\", values_from = \"StatMomentsAreaLogNormSum\")\n",
    "\n",
    "\n",
    "aggregated_proteomic_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generated protein table can be used as input to the software [pmartR](https://shinyproxy.emsl.pnnl.gov/app/pmart), which performs statistical analyses such as ANOVA and independence of missing data (IMD) tests. In this case, the aggregated proteomics table (`aggregated_proteomic_output`) would be equivalent to pmartR's `e_data` and the peptide to protein to gene mappings (`razor_mapping`) would be equivalent to pmartR's `e_meta`.\n",
    "\n",
    "<img src=\"../pmartR_logo_final.jpg\" width=\"25%\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pmartR requires sample metadata to parameterize analyses and interpret the data. For this example dataset, an API call will capture the biosample metadata (`sample_metadata`) that would be equivalent to pmartR's `f_data`.\n",
    "\n",
    "Gather biosample metadata via the NMDC API `collection` endpoint, using the function get_id_results() in api_func and searching for the `biosample_id`s associated with each output in `proteomic_output_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "biosample_metadata <- get_results_by_id(collection = \"biosample_set\",\n",
    "                                        match_id_field = \"id\", \n",
    "                                        id_list = proteomic_output_df$biosample_id, \n",
    "                                        fields = \"id,depth.has_numeric_value\") %>%\n",
    "  # Cleanup json output\n",
    "  unnest(depth) %>%\n",
    "  dplyr::rename(biosample_id = id,\n",
    "                depth_m = has_numeric_value) %>%\n",
    "  # Add data object IDs to connect biosample metadata to processed results\n",
    "  left_join(select(proteomic_output_df, processed_dobj_id, biosample_id), by = join_by(\"biosample_id\"))\n",
    "\n",
    "biosample_metadata"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "kernelspec"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
