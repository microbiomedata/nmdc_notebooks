{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca6d9cc3-0d70-41d8-9cfe-9253ec786894",
   "metadata": {},
   "source": [
    "# How does the taxonomic distribution of contigs differ by soil layer (mineral vs organic) in Colorado?\n",
    "\n",
    "This notebook uses the existing NMDC-runtime API endpoints (as of May 2024) to explore how the taxononomic distribution of metagenome contigs differ by the mineral and organic soil layers in Colorado. It involves 9 API requests to reach the scaffold lineage TSV data objects in order to analyze the taxanomic distribution. Iterating through the TSV files includes 100+ API calls to get the necessary taxonomic counts and is time consuming. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "568d7112-ee43-41ce-aadb-39eaa9585dbd",
   "metadata": {
    "metadata": {},
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Load essential libraries\n",
    "library(jsonlite, warn.conflicts=FALSE)\n",
    "library(dplyr, warn.conflicts=FALSE)\n",
    "library(tidyr, warn.conflicts=FALSE)\n",
    "library(readr, warn.conflicts=FALSE)\n",
    "library(ggplot2, warn.conflicts=FALSE)\n",
    "source(\"../../utility_functions.R\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3494f01-ac01-4eac-85d5-728622ddac6b",
   "metadata": {},
   "source": [
    "# 1. Get all biosamples where soil_horizon exists and the geo_loc_name has \"Colorado\" in the name\n",
    "\n",
    "The first step in answering how the taxonomic distribution of contigs differ by soil layer is to get a list of all the biosamples that have metadata for soil_horizon and a string matching \"Colorado, Rocky Mountains\" for the geo_loc_name. We use the `get_next_results` function (defined in `utility_functions.R`) to do this. We query the biosample_set collection with a mongo-like filter of {\"soil_horizon\":{\"$exists\": true}, \"geo_loc_name.has_raw_value\": {\"$regex\": \"Colorado\"}}, a maximum page size of 100, and specifying that we want three fields returned id, soil_horizon, and geo_loc_name. Note that id is always returned. Since we will be joining the results of multiple API requests with a field of id for different collections, we can change the name of the id key to be more explicit - calling it biosample_id instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780eae36-3f46-4c3e-bd26-b2a33c463441",
   "metadata": {
    "metadata": {},
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Get biosamples using get_next_results function\n",
    "biosample_df <- get_next_results(\n",
    "    collection = 'biosample_set', \n",
    "    filter_text = '{\"soil_horizon\":{\"$exists\": true}, \"geo_loc_name.has_raw_value\": {\"$regex\": \"Colorado\"}}', \n",
    "    max_page_size = 100, \n",
    "    fields = 'id,soil_horizon,geo_loc_name'\n",
    "    )\n",
    "\n",
    "# Clarify the column names\n",
    "biosample_df <- biosample_df %>%\n",
    "    unnest(\n",
    "        cols = c(\n",
    "            geo_loc_name\n",
    "        ), names_sep = \"_\") %>% \n",
    "    rename(biosample_id = id,\n",
    "           geo_loc_name = geo_loc_name_has_raw_value)\n",
    "head(biosample_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f512f80-3f14-481c-a28c-f6797fc61882",
   "metadata": {},
   "source": [
    "# 2. Get all Pooling results where the Pooling `has_input` are the biosample ids\n",
    "We use the `get_results_by_id` function to get a list of all pooling results whose field, `has_input` are the `biosample_id`s we retrieved in step 1. After, the pooling results are unnested to a flat data frame, andthe names are cleaned up so it is clear which collection the results are from. Because `Pooling` is a subclass of `MaterialProcessing` the pooling records are found in the `material_processing_set`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fc4389-49d8-42ea-a56b-a561c01900ff",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "pooling_df <- get_results_by_id(\n",
    "    collection = 'material_processing_set',\n",
    "    match_id_field = 'has_input',\n",
    "    id_list = biosample_df$biosample_id,\n",
    "    fields = 'id,has_input,has_output',\n",
    "    max_id = 20\n",
    ")\n",
    "\n",
    "# Unnest the has_input and has_output columns, get unique results, and rename the columns.\n",
    "pooling_df2 <- pooling_df %>%\n",
    "    unnest(\n",
    "        cols = c(\n",
    "            has_input,\n",
    "            has_output\n",
    "        ), names_sep = \"_\") %>%\n",
    "    distinct() %>%\n",
    "    rename(pooling_id = id,\n",
    "           biosample_id = has_input,\n",
    "           pooling_has_output = has_output)\n",
    "head(pooling_df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6faa60ca-c102-4be9-a5ee-60a350b6503c",
   "metadata": {},
   "source": [
    "Merge the biosample and pooling dataframes together to get a dataframe with biosample and pooling data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa58275-a5e6-418f-a04c-b1ef5e21f65e",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "biosample_df2 <- left_join(biosample_df, pooling_df2, by = 'biosample_id')\n",
    "head(biosample_df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44466bf-519c-4edf-bb15-1e641247e9a2",
   "metadata": {},
   "source": [
    "From the `pooling_has_output` IDs (all starting with *\"nmdc:procsm\"*), we can tell that the output from the pooling step is a `ProcessedSample`.  Therefore, we will rename the column from `pooling_has_output` to `processed_sample_id`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37534e80-aab9-4ec7-9829-8cde11e27a51",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "biosample_df3 <- biosample_df2 %>%\n",
    "    rename(processed_sample_id = pooling_has_output) \n",
    "head(biosample_df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7075cf7a-9f4d-41d8-9360-383f451e9573",
   "metadata": {},
   "source": [
    "# 3. Get `Extraction` records where `processed_sample_id` identifier is the `has_input` to the `Extraction`\n",
    "\n",
    "The `get_id_results` function is used, again (you can see the pattern), againe querying the `material_processing_set` (becuase `Extration` records are also a subclass of `MaterialProcessing` using the `processed_sample1` identifier as the `has_input` for the `material_processing_set`. The resulting dataframe is unnested and the names are adjusted to make it clear which set the inputs, outputs, and ids are from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832c3ddd-6db6-4292-8325-fc812e156346",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "extraction_df <- get_results_by_id(\n",
    "    collection = 'material_processing_set',\n",
    "    match_id_field = 'has_input',\n",
    "    id_list = unique(biosample_df3$processed_sample_id),\n",
    "    fields = 'id,has_input,has_output',\n",
    "    max_id = 20\n",
    ")\n",
    "\n",
    "extraction_df <- extraction_df %>%\n",
    "    unnest(\n",
    "        cols = c(\n",
    "            has_input,\n",
    "            has_output\n",
    "        ), names_sep = \"_\") %>%\n",
    "    distinct() %>%\n",
    "    rename(extraction_id = id,\n",
    "           processed_sample_id = has_input,\n",
    "           extraction_has_output = has_output)\n",
    "head(extraction_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d4735a-24a3-4df4-b2df-e230afde1391",
   "metadata": {},
   "source": [
    "Merge the extraction data with the biosample, pooling, and processed sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8842cde0-c0ab-4bba-8c8e-fcba2b77a4cd",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "biosample_df4 <- biosample_df3 %>%\n",
    "    left_join(extraction_df, by = join_by(processed_sample_id))\n",
    "head(biosample_df4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f8874f-b45a-42d3-a58b-accf6cba85ec",
   "metadata": {},
   "source": [
    "From the `extraction_has_output` IDs (all starting with *\"nmdc:procsm\"*), we can tell that the output from the extraction step is a `ProcessedSample`.  Therefore, we will rename the column from `extraction_has_output` to `processed_sample_id2`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc982cf2-08a1-4bfe-9cf3-7ca550f46790",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "biosample_df5 <- biosample_df4 %>%\n",
    "    rename(processed_sample_id2 = extraction_has_output)\n",
    "head(biosample_df5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4b7090-5dab-4f7d-a651-31c8af20e5a9",
   "metadata": {},
   "source": [
    "# 4. Get the `LibraryPreparation` records\n",
    "\n",
    "Using the `processed_sample_id2` identifiers from the last query as the `has_input` again for the the `material_processing_set` (becuase `LibraryPreparation` is a subclass of `MaterialProcessing`), we get a new batch of results, returning the library preparation identifiers, inputs and outputs. The results is unnested and names are clarified to demonstrate they are associated with `LibraryPreparation` records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e627fa-72ad-4e64-baf9-471443ba7168",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library_prep_df <- get_results_by_id(\n",
    "    collection = 'material_processing_set',\n",
    "    match_id_field = 'has_input',\n",
    "    id_list = unique(biosample_df5$processed_sample_id2),\n",
    "    fields = 'id,has_input,has_output',\n",
    "    max_id = 20\n",
    ")\n",
    "\n",
    "library_prep_df <- library_prep_df %>%\n",
    "    unnest(\n",
    "        cols = c(\n",
    "            has_input,\n",
    "            has_output\n",
    "        ), names_sep = \"_\") %>%\n",
    "    distinct() %>%\n",
    "    rename(library_preparation_id = id,\n",
    "           processed_sample_id2 = has_input,\n",
    "           library_preparation_has_output = has_output)\n",
    "head(library_prep_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cb83e8-1907-4b88-9361-fa2903ec5dd0",
   "metadata": {},
   "source": [
    "Merge the library preparation data with the biosample, pooling, processed sample, extraction, and processed sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8506d2d-356d-4277-9711-052296ecfae4",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "biosample_df6 <- biosample_df5 %>%\n",
    "    left_join(library_prep_df, by = join_by(processed_sample_id2))\n",
    "head(biosample_df6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929a259a-2957-41c1-9f43-08d52120242f",
   "metadata": {},
   "source": [
    "Again, from the `library_preparation_has_output` IDs (all starting with *\"nmdc:procsm\"*), we can tell that the output to the library preparation step is a `ProcessedSample`.  Therefore, we will rename the column from `library_preparation_has_output` to `processed_sample_id3`. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667690ba-a598-4f72-9c21-9ff8a6c28b8c",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "biosample_df7 <- biosample_df6 %>%\n",
    "    rename(processed_sample_id3 = library_preparation_has_output)\n",
    "head(biosample_df7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697a66f9-471e-40f0-99df-376174824fc6",
   "metadata": {},
   "source": [
    "# 5. Get `NucleotideSequencing` records from the processed sample identifiers\n",
    "\n",
    "Using the third batch of processed sample identifiers, we query the `data_generataion_set` on the `has_input` field to retreive `NucleotideSequencing` record (because `NucleotideSequencing` is a subclass of `DataGeneration`). The `id` and `has_input` field names are changed to specify that they came from the `NucleotideSequencing` records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be09a8ef-d0fb-4df8-bef3-bc8498f3d444",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "data_generation_df <- get_results_by_id(\n",
    "    collection = 'data_generation_set',\n",
    "    match_id_field = 'has_input',\n",
    "    id_list = unique(biosample_df7$processed_sample_id3),\n",
    "    fields = 'id,has_input',\n",
    "    max_id = 20\n",
    ")\n",
    "\n",
    "data_generation_df <- data_generation_df %>%\n",
    "    unnest(\n",
    "        cols = c(\n",
    "            has_input\n",
    "        ), names_sep = \"_\") %>%\n",
    "    rename(data_generation_id = id,\n",
    "           processed_sample_id3 = has_input)\n",
    "head(data_generation_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a95303-8bba-4ecf-8b9f-fd78a43ee402",
   "metadata": {},
   "source": [
    "Merge the omics processing data with the biosample, pooling, processed sample, extraction, processed sample, library preparation, and processed sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6c028e-4260-4324-8fb3-0402216d2f7f",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "biosample_df8 <- biosample_df7 %>%\n",
    "    left_join(data_generation_df, by = join_by(processed_sample_id3))\n",
    "head(biosample_df8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e0ec5b-b831-460a-be9f-b0e1099e266f",
   "metadata": {},
   "source": [
    "# 6. Get the `MetagenomeAnnotation` ids using the `DataGeneration` identifiers\n",
    "\n",
    "The `workflow_execution_set` is queried to retreive `MetagenomeAnnotation` records (because `MetagenomeAnnotation` is a subclass of `WorkflowExecution`) using the identifiers obtained from the data generation to match with the `was_informed_by` field in the `workflow_execution_set`. Field names are clarified, once again to specify the collection they came from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6328c9a8-ee49-4dc4-b1e3-b530f718c371",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "metagenome_annotation_df <- get_results_by_id(\n",
    "    collection = 'workflow_execution_set',\n",
    "    match_id_field = 'was_informed_by',\n",
    "    id_list = unique(biosample_df8$data_generation_id),\n",
    "    fields = 'id,was_informed_by,has_output,type',\n",
    "    max_id = 20\n",
    ")\n",
    "head(metagenome_annotation_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da008e52-597d-4c7f-bd63-6d3429f6a5e5",
   "metadata": {},
   "source": [
    "This query resulted in all the workflows associated with the `DataGeneration` identifiers.  We can investigate the different types of workflows assoaciated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4637e99-8950-441a-9966-e31e7781fa21",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "unique(metagenome_annotation_df$type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219a0a54-c830-42b4-b968-335250a6feaa",
   "metadata": {},
   "source": [
    "We are only interested in the outputs of the `MetagenomeAnnotation` workflow, so we'll filter our dataframe to only these results and clean it up for the next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24529f53-c27d-4948-824f-ad5a7a9d405c",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "metagenome_annotation_df <- metagenome_annotation_df %>%\n",
    "    filter(type == \"nmdc:MetagenomeAnnotation\") %>%\n",
    "    unnest(\n",
    "        cols = c(\n",
    "            was_informed_by,\n",
    "            has_output\n",
    "        ), names_sep = \"_\") %>%\n",
    "    rename(metagenome_annotation_id = id,\n",
    "           data_generation_id = was_informed_by,\n",
    "           matagenome_annotation_has_output = has_output,\n",
    "           workflow_type = type)\n",
    "head(metagenome_annotation_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e67c4b5-4c92-4331-9072-9a65d7ae52bd",
   "metadata": {},
   "source": [
    "Merge the metagenome annotation data with the biosample, pooling, processed sample, extraction, processed sample, library preparation, processed sample, omics processing, and processed sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa89e83-67de-4620-ba98-a15311882551",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "biosample_df9 <- biosample_df8 %>%\n",
    "    left_join(metagenome_annotation_df, by = join_by(data_generation_id), relationship = \"many-to-many\")\n",
    "head(biosample_df9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814da9fb-b162-485e-b319-ee47e81920fc",
   "metadata": {},
   "source": [
    "# 7. Get data objects from the metagenome activity result outputs\n",
    "\n",
    "We query the `data_object_set` using the `matagenome_annotation_has_output` identifiers to match the `id` field in the data objects. We then filter the results for only those results with a `data_object_type` of `Scaffold Lineage tsv` (since this has contig taxonomy results). Note that the `url` is a new field returned that contains the tsvs we will need for the final analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1f3a9c-ba08-43a6-b9aa-577ec7586969",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "data_object_df <- get_results_by_id(\n",
    "    collection = 'data_object_set',\n",
    "    match_id_field = 'id',\n",
    "    id_list = unique(biosample_df9$matagenome_annotation_has_output),\n",
    "    fields = 'id,data_object_type,url',\n",
    "    max_id = 50\n",
    ")\n",
    "\n",
    "# Filter the data object results to only include the Scaffold Lineage tsv files\n",
    "data_object_df <- data_object_df %>%\n",
    "    rename(data_object_id = id) %>%\n",
    "    filter(data_object_type == 'Scaffold Lineage tsv')\n",
    "head(data_object_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2825237d-c5ad-4777-9db9-b4e7e5c68b6c",
   "metadata": {},
   "source": [
    "Merge the data object data with the biosample, pooling, processed sample, extraction, processed sample, library preparation, processed sample, data generation, processed sample, and metagenome annotation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ac4d7e-861f-4553-b05c-751ae08d2304",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "biosample_df10 <- biosample_df9 %>%\n",
    "    rename(data_object_id = matagenome_annotation_has_output) %>%\n",
    "    left_join(data_object_df, by = join_by(data_object_id))\n",
    "head(biosample_df10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56eedef-1f56-451d-99f6-9940ed6ba44e",
   "metadata": {},
   "source": [
    "## Clean up the combined results\n",
    "\n",
    "In the final step of retrieving and cleaning the data, we clean up the final merged data frame by removing all of the \"joining columns\" that are not needed in our final analysis. Because some of the biosamples were pooled, we only retain unique url results (and drop the `biosample_id` column). The only columns we retain are the `soil_horizon`, `geo_loc_name`, and the `url` to the tsv. The `final_df` is displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9444e91a-1305-4a15-ae8d-338ca54eb5e4",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "biosample_df_final <- biosample_df10 %>%\n",
    "    select(biosample_id, soil_horizon, geo_loc_name, data_object_id, data_object_type, url) %>%\n",
    "    distinct() %>%\n",
    "    filter(!is.na(url))\n",
    "head(biosample_df_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8706411-d4ac-45df-b443-ae113d98421e",
   "metadata": {},
   "source": [
    "## Show how many results have M horizon vs. O horizon\n",
    "\n",
    "The `soil_horizon` column can be counted using the `count()` functionality. There are many more samples with associated Scaffold Lineage tsvs from a M horizon biosample than a O horizon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7521a8c4-7b02-4d4b-a0c4-4287bc814516",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "biosample_df_final %>%\n",
    "    count(soil_horizon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cfdca2-5d15-4f40-96e9-5a0454ac2d56",
   "metadata": {},
   "source": [
    "## Example of what the TSV contig taxa file looks like\n",
    "\n",
    "A snippet of the TSV file we need to iterate over to get the taxa abundance for the contigs is shown below. The third column is the initial count for the taxa, where each row is `1.0`. However, there are duplicate rows of taxa, meaning there are actually more than `1.0` for several taxa (though they appear as duplicate rows with `1.0` as the count`). We will take this into consideration when we calculate the relative abundance for each taxa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c7457f-c1dc-4344-8049-581eee81ffd2",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "url <- biosample_df_final$url[1]\n",
    "\n",
    "# Read the TSV file\n",
    "contig_taxa_df <- read_tsv(url, col_names = FALSE, show_col_types = FALSE)\n",
    "\n",
    "# Add column names \n",
    "colnames(contig_taxa_df) <- c('contig_id', 'taxa', 'initial_count')\n",
    "\n",
    "# Show the first few rows\n",
    "head(contig_taxa_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484d4ab1-bdf9-4d60-898f-e178daea0c42",
   "metadata": {},
   "source": [
    "## Iterate throught the TSVs to get the contig taxa information\n",
    "\n",
    "Using the readr's `read_tsv` function, the TSV urls can be iterated over gathering the taxa information. The TSVs are converted into dataframes where they are manipulated to suit the data structure needed. The columns are given names and the taxa column is split into a proper list (instead of a string of items separated by a semicolon ;). The third element from the list of taxa is retrieved to get only the phylum level information of the taxa (or unknown to the highest available taxon). A grouping function is performed on the `taxa` column and the `count()` functionality is used to calculate the count for how many times each taxa occurs, which is then used to calculate the relative abundance of each taxa for each sample. \n",
    "\n",
    "Any errors in requesting the TSV urls are collected as a dictionary, so we can either try to query them again, or look into why they were not able to be collected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a331e72-182c-4a55-b1e9-705908b6238d",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "urls <- unique(biosample_df_final$url)\n",
    "results_list <- c()\n",
    "error_dict <- list()\n",
    "\n",
    "for (i in 1:length(urls)) {\n",
    "    # if i a factor of 100, print the progress\n",
    "    if (i %% 10 == 0) {\n",
    "        print(paste('Processing', i, 'of', length(urls)))\n",
    "    }\n",
    "    url <- urls[i]\n",
    "    tryCatch({\n",
    "        contig_taxa_df <- read_tsv(url, col_names = FALSE, show_col_types = FALSE)\n",
    "        colnames(contig_taxa_df) <- c('contig_id', 'taxa', 'initial_count')\n",
    "        \n",
    "        # Clean up the taxa column and deal with unknown taxa\n",
    "        contig_taxa_df$taxa_new <- contig_taxa_df$taxa\n",
    "        contig_taxa_df$taxa_new <- sapply(strsplit(contig_taxa_df$taxa_new, ';'), function(x) x[3])\n",
    "        contig_taxa_df$taxa_new <- ifelse(\n",
    "            is.na(contig_taxa_df$taxa_new), \n",
    "            paste('Unknown', sapply(strsplit(contig_taxa_df$taxa, ';'), function(x) x[2])), \n",
    "            contig_taxa_df$taxa_new)\n",
    "        contig_taxa_df$taxa_new <- ifelse(\n",
    "            contig_taxa_df$taxa_new == \"Unknown NA\", \n",
    "            paste('Unknown', sapply(strsplit(contig_taxa_df$taxa, ';'), function(x) x[1])), \n",
    "            contig_taxa_df$taxa_new)\n",
    "        contig_taxa_df$taxa <- contig_taxa_df$taxa_new\n",
    "\n",
    "        contig_taxa_df <- contig_taxa_df %>%\n",
    "            group_by(taxa) %>%\n",
    "            summarise(count = n()) %>%\n",
    "            mutate(relative_abundance = count / sum(count))\n",
    "\n",
    "        # Add the queried url to the dataframe for later joining\n",
    "        contig_taxa_df$url <- url\n",
    "        results_list[[i]] <- contig_taxa_df\n",
    "\n",
    "    }, error = function(e) {\n",
    "        error_dict[[i]] <- e\n",
    "    })\n",
    "}\n",
    "\n",
    "# Combine results into single dataframe\n",
    "contig_df <- bind_rows(results_list) \n",
    "\n",
    "head(contig_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f425cddd-6a17-4ebb-bf0d-415df07f28ad",
   "metadata": {},
   "source": [
    "## Clean up the relative abundance data to fill in NAs with 0 for unobserved taxa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dae25f8c-ffb9-43a7-8b9b-9464d3e9b8b9",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# First merge to get the url for geo_loc_name and soil_horizon\n",
    "biosample_taxa_df <- biosample_df_final %>%\n",
    "    select(soil_horizon, geo_loc_name, url) %>%\n",
    "    distinct() %>%\n",
    "    right_join(contig_df, by = join_by(url))\n",
    "\n",
    "# Then pivot the table to fill in the relative abundance as zero for un-observed taxa\n",
    "biosample_taxa_df_wide <- biosample_taxa_df %>%\n",
    "    pivot_wider(id_cols = c(url, soil_horizon, geo_loc_name),\n",
    "        names_from = taxa, values_from = relative_abundance) %>%\n",
    "    replace(is.na(.), 0)\n",
    "\n",
    "# And unpivot the table to get the taxa relative abundance for each biosample\n",
    "biosample_taxa_df <- biosample_taxa_df_wide %>%\n",
    "    pivot_longer(cols = -c(url, soil_horizon, geo_loc_name), names_to = 'taxa', values_to = 'relative_abundance')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b143ea72-6869-4d82-987b-8b7281fb3806",
   "metadata": {},
   "source": [
    "## Plot the average taxa abundance for all M and O horizon soil samples\n",
    "First calculate the average relative abundance for each taxa in each soil horizon.  Next, we'll pull out the top ten taxa and lump all others into an \"Other\" category for plotting purposes using the `forcats::fct_other` function.  Then we'll calculate the mean relative abundance of each taxa for each soil horizon. Finally, we'll choose an appropriate color palette for the plot, and plot the relative abundance of each taxa for each soil horizon at each location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460474ef-2d2e-4553-85fc-78dc5a756bf1",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "options(dplyr.summarise.inform = FALSE)\n",
    "horizon_taxa <- biosample_taxa_df %>%\n",
    "    group_by(soil_horizon, taxa) %>%\n",
    "    summarise(mean_relative_abundance = mean(relative_abundance))%>%\n",
    "    arrange(mean_relative_abundance) %>%\n",
    "    mutate(taxa = factor(taxa, levels = rev(unique(taxa)))) %>%\n",
    "    mutate(taxa_lump = forcats::fct_other(taxa, keep = levels(taxa)[1:15], other_level = 'Other')) \n",
    "           \n",
    "# Make color palette that is 9 colors long, and followed with grey\n",
    "color_pal <- c(RColorBrewer::brewer.pal(8, 'Set1'), RColorBrewer::brewer.pal(7, 'Set3'), 'grey')\n",
    "g <- ggplot(horizon_taxa, aes(x = soil_horizon, y = mean_relative_abundance, fill = taxa_lump)) +\n",
    "    geom_bar(stat = 'identity', color = NA) +\n",
    "    theme(axis.text.x = element_text(angle = 90, hjust = 1)) +\n",
    "    labs(title = 'Taxa abundance of M and O horizon soil samples',\n",
    "         x = 'Soil Horizon', y = 'Mean relative abundance', fill = NULL) +\n",
    "    scale_fill_manual(values = color_pal) +\n",
    "    theme_minimal() \n",
    "options(repr.plot.width = 7, repr.plot.height = 7, repr.plot.res = 250)\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12922925-eabe-436c-ab87-37fbb734ca88",
   "metadata": {},
   "source": [
    "## Plot the taxa abundance of M and O horizon soil samples for each location\n",
    "First we'll pull out the top ten taxa and lump all others into an \"Other\" category for plotting purposes using the `forcats::fct_other` function.  Then we'll calculate the mean relative abundance of each taxa for each soil horizon for each location. Finally, we'll plot the relative abundance of each taxa for each soil horizon at each location (using the same color palette as above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8211c8-93cd-4be7-8fc5-1bbcc30187ab",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "geo_taxa <- biosample_taxa_df %>%\n",
    "    group_by(geo_loc_name, soil_horizon, taxa) %>%\n",
    "    summarise(mean_relative_abundance = mean(relative_abundance)) %>%\n",
    "    arrange(mean_relative_abundance) %>%\n",
    "    mutate(taxa = factor(taxa, levels = rev(unique(taxa)))) %>%\n",
    "    mutate(taxa_lump = forcats::fct_other(taxa, keep = levels(taxa)[1:15], other_level = 'Other')) %>%\n",
    "    mutate(soil_horizon = factor(soil_horizon, levels = c('M horizon', 'O horizon'), labels = c('M', 'O')))\n",
    "\n",
    "g <- ggplot(geo_taxa, aes(x = soil_horizon, y = mean_relative_abundance, fill = taxa_lump)) +\n",
    "    geom_bar(stat = 'identity', color = NA) +\n",
    "    facet_wrap(~geo_loc_name, nrow = 1,labeller =  label_wrap_gen(width = 20, multi_line = TRUE)) +\n",
    "    labs(title = 'Taxa abundance of M and O horizon soil samples for each location',\n",
    "         x = 'Soil Horizon', y = 'Mean relative abundance', fill = NULL) +\n",
    "    scale_fill_manual(values = color_pal) +\n",
    "    theme_minimal()+\n",
    "    theme(axis.text.x = element_text(angle = 90, hjust = 1),\n",
    "          legend.position = \"bottom\") \n",
    "options(repr.plot.width = 9, repr.plot.height = 7, repr.plot.res = 250)\n",
    "g"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
