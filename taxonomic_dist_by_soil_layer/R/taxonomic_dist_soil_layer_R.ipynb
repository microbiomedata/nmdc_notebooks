{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca6d9cc3-0d70-41d8-9cfe-9253ec786894",
   "metadata": {},
   "source": [
    "# How does the taxonomic distribution of contigs differ by soil layer (mineral vs organic) in Colorado?\n",
    "\n",
    "This notebook uses the existing NMDC-runtime API endpoints (as of May 2024) to explore how the taxononomic distribution of metagenome contigs differ by the mineral and organic soil layers in Colorado. It involves 9 API requests to reach the scaffold lineage TSV data objects in order to analyze the taxanomic distribution. Iterating through the TSV files includes 100+ API calls to get the necessary taxonomic counts and is time consuming. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "568d7112-ee43-41ce-aadb-39eaa9585dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load essential libraries\n",
    "library(jsonlite, warn.conflicts=FALSE)\n",
    "library(dplyr, warn.conflicts=FALSE)\n",
    "library(tidyr, warn.conflicts=FALSE)\n",
    "library(readr, warn.conflicts=FALSE)\n",
    "library(ggplot2, warn.conflicts=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ba287e-e606-4a50-949c-07aac9892473",
   "metadata": {},
   "source": [
    "## Define a general API call funtion to nmdc-runtime\r",
    "\r",
    "This function provides a general-purpose way to make an API request to NMDC's runtime API. Note that this function will only return the first page of results. The function's input includes the name of the collection to access (e.g. biosample_set), the filter to be performed, the maximum page size, and a list of the fields to be retrieved. It returns the metadata as a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ab6df9b-aaa0-4898-9095-a15efc867bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_first_page_results <- function(collection, filter, max_page_size, fields) {\n",
    "  og_url <- paste0(\n",
    "      'https://api.microbiomedata.org/nmdcschema/', \n",
    "      collection, '?&filter=', filter, '&max_page_size=', max_page_size, '&projection=', fields\n",
    "      )\n",
    "  \n",
    "  response <- jsonlite::fromJSON(URLencode(og_url, repeated = TRUE))\n",
    "  \n",
    "  return(response)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a306a7c-d48c-42bc-8da7-fb134a0c6b2c",
   "metadata": {},
   "source": [
    "## Define an nmdc-runtime API call function to include pagination\r",
    "\r",
    "The get_next_results function uses the get_first_page_results function, defined above, to retrieve the rest of the results from a call with multiple pages. It takes the same inputs as the get_first_page_results function above: the name of the collection to be retrieved, the filter string, the maximum page size, and a list of the fields to be returned. This function returns the results as a single dataframe (can be nested). It uses the next_page_token key in each page of results to retrieve the following page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8af9945b-37c1-49ed-9a8b-dc85a52692eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_next_results <- function(collection, filter_text, max_page_size, fields) {\n",
    "  initial_data <- get_first_page_results(collection, filter_text, max_page_size, fields)\n",
    "  results_df <- initial_data$resources\n",
    "  \n",
    "  if (!is.null(initial_data$next_page_token)) {\n",
    "    next_page_token <- initial_data$next_page_token\n",
    "    \n",
    "    while (TRUE) {\n",
    "      url <- paste0('https://api.microbiomedata.org/nmdcschema/', collection, '?&filter=', filter_text, '&max_page_size=', max_page_size, '&page_token=', next_page_token, '&projection=', fields)\n",
    "      response <- jsonlite::fromJSON(URLencode(url, repeated = TRUE))\n",
    "\n",
    "      results_df <- results_df %>% bind_rows(response$resources)\n",
    "      next_page_token <- response$next_page_token\n",
    "      \n",
    "      if (is.null(next_page_token)) {\n",
    "        break\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  return(results_df)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3494f01-ac01-4eac-85d5-728622ddac6b",
   "metadata": {},
   "source": [
    "# 1. Get all biosamples where soil_horizon exists and the geo_loc_name has \"Colorado\" in the name\n",
    "\n",
    "The first step in answering how the taxonomic distribution of contigs differ by soil layer is to get a list of all the biosamples that have metadata for soil_horizon and a string matching \"Colorado, Rocky Mountains\" for the geo_loc_name. We use the get_next_results function (defined above) to do this. We query the biosample_set collection with a mongo-like filter of {\"soil_horizon\":{\"$exists\": true}, \"geo_loc_name.has_raw_value\": {\"$regex\": \"Colorado\"}}, a maximum page size of 100, and specifying that we want three fields returned id, soil_horizon, and geo_loc_name. Note that id is always returned. Since we will be joining the results of multiple API requests with a field of id for different collections, we can change the name of the id key to be more explicit - calling it biosample_id instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "780eae36-3f46-4c3e-bd26-b2a33c463441",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in open.connection(con, \"rb\"):\n",
      "“cannot open URL 'https://api.microbiomedata.org/nmdcschema/biosample_set?&filter=%7B%22soil_horizon%22:%7B%22$exists%22:%20true%7D,%20%22geo_loc_name.has_raw_value%22:%20%7B%22$regex%22:%20%22Colorado%22%7D%7D&max_page_size=100&projection=id,soil_horizon,geo_loc_name': HTTP status was '503 Service Unavailable'”\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in open.connection(con, \"rb\"): cannot open the connection to 'https://api.microbiomedata.org/nmdcschema/biosample_set?&filter=%7B%22soil_horizon%22:%7B%22$exists%22:%20true%7D,%20%22geo_loc_name.has_raw_value%22:%20%7B%22$regex%22:%20%22Colorado%22%7D%7D&max_page_size=100&projection=id,soil_horizon,geo_loc_name'\n",
     "output_type": "error",
     "traceback": [
      "Error in open.connection(con, \"rb\"): cannot open the connection to 'https://api.microbiomedata.org/nmdcschema/biosample_set?&filter=%7B%22soil_horizon%22:%7B%22$exists%22:%20true%7D,%20%22geo_loc_name.has_raw_value%22:%20%7B%22$regex%22:%20%22Colorado%22%7D%7D&max_page_size=100&projection=id,soil_horizon,geo_loc_name'\nTraceback:\n",
      "1. get_next_results(collectio = \"biosample_set\", filter_text = \"{\\\"soil_horizon\\\":{\\\"$exists\\\": true}, \\\"geo_loc_name.has_raw_value\\\": {\\\"$regex\\\": \\\"Colorado\\\"}}\", \n .     max_page_size = 100, fields = \"id,soil_horizon,geo_loc_name\")",
      "2. get_first_page_results(collection, filter_text, max_page_size, \n .     fields)   # at line 2 of file <text>",
      "3. jsonlite::fromJSON(URLencode(og_url, repeated = TRUE))   # at line 7 of file <text>",
      "4. parse_and_simplify(txt = txt, simplifyVector = simplifyVector, \n .     simplifyDataFrame = simplifyDataFrame, simplifyMatrix = simplifyMatrix, \n .     flatten = flatten, ...)",
      "5. parseJSON(txt, bigint_as_char)",
      "6. parse_con(txt, bigint_as_char)",
      "7. open(con, \"rb\")",
      "8. open.connection(con, \"rb\")"
     ]
    }
   ],
   "source": [
    "# Get biosamples using get_next_results function\n",
    "biosample_df <- get_next_results(\n",
    "    collectio = 'biosample_set', \n",
    "    filter_text = '{\"soil_horizon\":{\"$exists\": true}, \"geo_loc_name.has_raw_value\": {\"$regex\": \"Colorado\"}}', \n",
    "    max_page_size = 100, \n",
    "    fields = 'id,soil_horizon,geo_loc_name'\n",
    "    )\n",
    "\n",
    "# Clarify the column names\n",
    "biosample_df <- biosample_df %>%\n",
    "    unnest(\n",
    "        cols = c(\n",
    "            geo_loc_name\n",
    "        ), names_sep = \"_\") %>% \n",
    "    rename(biosample_id = id,\n",
    "           geo_loc_name = geo_loc_name_has_raw_value)\n",
    "head(biosample_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a8bc8e-14eb-4844-b8ce-34b1ed7a0773",
   "metadata": {},
   "source": [
    "## Define an API request function that uses a list of ids to filter on\r",
    "This function constructs a different type of API request that takes a list of ids or similar (e.g. `biosample` ids as retreived above). The `id_field` input is a string of the name of the id field name (e.g. `id` or `has_output`), the name of the new collection to be queried, the name of the field to match the previous ids on in the new collection, and a list of the fields to be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce435021-79f1-4a1d-aef0-fea4bc267817",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_results_by_id <- function(collection, match_id_field, id_list, fields, max_id = 50) {\n",
    "    # collection: the name of the collection to query\n",
    "    # match_id_field: the field in the new collection to match to the id_list\n",
    "    # id_list: a list of ids to filter on\n",
    "    # fields: a list of fields to return\n",
    "    # max_id: the maximum number of ids to include in a single query\n",
    "    \n",
    "    # If id_list is longer than max_id, split it into chunks of max_id\n",
    "    if (length(id_list) > max_id) {\n",
    "        id_list <- split(id_list, ceiling(seq_along(id_list)/max_id))\n",
    "    } else {\n",
    "        id_list <- list(id_list)\n",
    "    }\n",
    "    \n",
    "    output <- list()\n",
    "    for (i in 1:length(id_list)) {\n",
    "        # Cast as a character vector and add double quotes around each ID\n",
    "        mongo_id_string <- as.character(id_list[[i]]) %>%\n",
    "            paste0('\"', ., '\"') %>%\n",
    "            paste(collapse = ', ')\n",
    "        \n",
    "        # Create the filter string\n",
    "        filter = paste0('{\"', match_id_field, '\": {\"$in\": [', mongo_id_string, ']}}')\n",
    "        \n",
    "        # Get the data\n",
    "        output[[i]] = get_next_results(\n",
    "            collection = collection,\n",
    "            filter = filter,\n",
    "            max_page_size = max_id*3, #assumes that there are no more than 3 records per query\n",
    "            fields = fields\n",
    "        )\n",
    "    }\n",
    "    output_df <- bind_rows(output)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f512f80-3f14-481c-a28c-f6797fc61882",
   "metadata": {},
   "source": [
    "# 2. Get all Pooling results where the Pooling `has_input` are the biosample ids\r",
    "We use the `get_results_by_id` function above to get a list of all pooling results whose field, `has_input` are the `biosample_id`s we retrieved in step 1. After, the pooling results are unnested to a flat data frame, andthe names are cleaned up so it is clear which collection the results are from. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8fc4389-49d8-42ea-a56b-a561c01900ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'biosample_df' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'biosample_df' not found\nTraceback:\n",
      "1. get_results_by_id(collection = \"pooling_set\", match_id_field = \"has_input\", \n .     id_list = biosample_df$biosample_id, fields = \"id,has_input,has_output\", \n .     max_id = 20)"
     ]
    }
   ],
   "source": [
    "pooling_df <- get_results_by_id(\n",
    "    collection = 'pooling_set',\n",
    "    match_id_field = 'has_input',\n",
    "    id_list = biosample_df$biosample_id,\n",
    "    fields = 'id,has_input,has_output',\n",
    "    max_id = 20\n",
    ")\n",
    "\n",
    "# Unnest the has_input and has_output columns, get unique results, and rename the columns.\n",
    "pooling_df2 <- pooling_df %>%\n",
    "    unnest(\n",
    "        cols = c(\n",
    "            has_input,\n",
    "            has_output\n",
    "        ), names_sep = \"_\") %>%\n",
    "    distinct() %>%\n",
    "    rename(pooling_id = id,\n",
    "           biosample_id = has_input,\n",
    "           pooling_has_output = has_output)\n",
    "head(pooling_df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6faa60ca-c102-4be9-a5ee-60a350b6503c",
   "metadata": {},
   "source": [
    "Merge the biosample and pooling dataframes together to get a dataframe with biosample and pooling data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0aa58275-a5e6-418f-a04c-b1ef5e21f65e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'biosample_df' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'biosample_df' not found\nTraceback:\n",
      "1. left_join(biosample_df, pooling_df2, by = \"biosample_id\")"
     ]
    }
   ],
   "source": [
    "biosample_df2 <- left_join(biosample_df, pooling_df2, by = 'biosample_id')\n",
    "head(biosample_df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44466bf-519c-4edf-bb15-1e641247e9a2",
   "metadata": {},
   "source": [
    "# 3. Get processed samples where the the processed sample `id`s are the `pooling_has_output` field\r",
    "\r",
    "We use the `get_results_by_id` function, again, to get a list of the processed sample results whose field, `pooling_has_output` are the processed sample ids. We will return the results only for the processed sample id field and clean up the names so it is clear that they are the identifiers from the `processed_sample_set`. Finally, the results are converted to a data frame and columns are renamed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed7dc4c6-3193-410c-aa94-8a78a4cd48b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'pooling_df2' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'pooling_df2' not found\nTraceback:\n",
      "1. get_results_by_id(collection = \"processed_sample_set\", match_id_field = \"id\", \n .     id_list = unique(pooling_df2$pooling_has_output), fields = \"id\", \n .     max_id = 20)",
      "2. unique(pooling_df2$pooling_has_output)   # at line 9-13 of file <text>"
     ]
    }
   ],
   "source": [
    "process_set1_df <- get_results_by_id(\n",
    "    collection = 'processed_sample_set',\n",
    "    match_id_field = 'id',\n",
    "    id_list = unique(pooling_df2$pooling_has_output),\n",
    "    fields = 'id',\n",
    "    max_id = 20\n",
    ")\n",
    "\n",
    "process_set1_df <- process_set1_df %>%\n",
    "    rename(processed_sample_id = id)\n",
    "head(process_set1_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef798f9-4d2c-45ec-82b8-d14d3f7c31e2",
   "metadata": {},
   "source": [
    "Merge the processed sample data with the biosample and pooling data, where the processed sample id is the same as the pooling_has_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37534e80-aab9-4ec7-9829-8cde11e27a51",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'biosample_df2' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'biosample_df2' not found\nTraceback:\n",
      "1. biosample_df2 %>% rename(processed_sample_id = pooling_has_output) %>% \n .     left_join(process_set1_df, by = join_by(processed_sample_id))",
      "2. left_join(., process_set1_df, by = join_by(processed_sample_id))",
      "3. rename(., processed_sample_id = pooling_has_output)"
     ]
    }
   ],
   "source": [
    "biosample_df3 <- biosample_df2 %>%\n",
    "    rename(processed_sample_id = pooling_has_output) %>%\n",
    "    left_join(process_set1_df, by = join_by(processed_sample_id))\n",
    "head(biosample_df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7075cf7a-9f4d-41d8-9360-383f451e9573",
   "metadata": {},
   "source": [
    "# 4. Get extraction results where `processed_sample1` identifier is the `has_input` to the `extraction_set`\r",
    "\r",
    "The `get_id_results` function is used, again (you can see the pattern), but this time to query the `extraction_set` using the `processed_sample1` identifier as the `has_input` for the `extraction_set`. The resulting dataframe is unnested and the names are adjusted to make it clear which set the inputs, outputs, and ids are from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832c3ddd-6db6-4292-8325-fc812e156346",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_df <- get_results_by_id(\n",
    "    collection = 'extraction_set',\n",
    "    match_id_field = 'has_input',\n",
    "    id_list = unique(biosample_df3$processed_sample_id),\n",
    "    fields = 'id,has_input,has_output',\n",
    "    max_id = 20\n",
    ")\n",
    "\n",
    "extraction_df <- extraction_df %>%\n",
    "    unnest(\n",
    "        cols = c(\n",
    "            has_input,\n",
    "            has_output\n",
    "        ), names_sep = \"_\") %>%\n",
    "    distinct() %>%\n",
    "    rename(extraction_id = id,\n",
    "           processed_sample_id = has_input,\n",
    "           extraction_has_output = has_output)\n",
    "head(extraction_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f8874f-b45a-42d3-a58b-accf6cba85ec",
   "metadata": {},
   "source": [
    "# 5. Get processed sample results from the output of the extraction results\r",
    "\r",
    "We query the `processed_sample_set` again, but this time using the `extract_has_output` ids to query the set. We only need to return the `processed_sample_set` identifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea7119d7-aa9c-4f70-b4b2-403c3283ade6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'biosample_df4' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'biosample_df4' not found\nTraceback:\n",
      "1. get_results_by_id(collection = \"processed_sample_set\", match_id_field = \"id\", \n .     id_list = unique(biosample_df4$extraction_has_output), fields = \"id\", \n .     max_id = 20)",
      "2. unique(biosample_df4$extraction_has_output)   # at line 9-13 of file <text>"
     ]
    }
   ],
   "source": [
    "process_set2_df <- get_results_by_id(\n",
    "    collection = 'processed_sample_set',\n",
    "    match_id_field = 'id',\n",
    "    id_list = unique(biosample_df4$extraction_has_output),\n",
    "    fields = 'id',\n",
    "    max_id = 20\n",
    ")\n",
    "\n",
    "process_set2_df <- process_set2_df %>%\n",
    "    rename(processed_sample_id2 = id)\n",
    "head(process_set2_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5067c92-1033-4bee-b492-64506d7dea2d",
   "metadata": {},
   "source": [
    "Merge the processed sample data with the biosample, pooling, processed sample, and extraction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc982cf2-08a1-4bfe-9cf3-7ca550f46790",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'biosample_df4' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'biosample_df4' not found\nTraceback:\n",
      "1. biosample_df4 %>% rename(processed_sample_id2 = extraction_has_output) %>% \n .     left_join(process_set2_df, by = join_by(processed_sample_id2))",
      "2. left_join(., process_set2_df, by = join_by(processed_sample_id2))",
      "3. rename(., processed_sample_id2 = extraction_has_output)"
     ]
    }
   ],
   "source": [
    "biosample_df5 <- biosample_df4 %>%\n",
    "    rename(processed_sample_id2 = extraction_has_output) %>%\n",
    "    left_join(process_set2_df, by = join_by(processed_sample_id2))\n",
    "head(biosample_df5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4b7090-5dab-4f7d-a651-31c8af20e5a9",
   "metadata": {},
   "source": [
    "# 6. Get the `library_preparation_set`\n",
    "\n",
    "Using the `processed_sample2` identifiers from the last query as the `has_input` for the the `library_preparation_set`, we get a new batch of results, returning the library preparation identifiers, inputs and outputs. The results is unnested and names are clarified to demonstrate they are from the `library_preparation_set`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5e627fa-72ad-4e64-baf9-471443ba7168",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'biosample_df5' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'biosample_df5' not found\nTraceback:\n",
      "1. get_results_by_id(collection = \"library_preparation_set\", match_id_field = \"has_input\", \n .     id_list = unique(biosample_df5$processed_sample_id2), fields = \"id,has_input,has_output\", \n .     max_id = 20)",
      "2. unique(biosample_df5$processed_sample_id2)   # at line 9-13 of file <text>"
     ]
    }
   ],
   "source": [
    "library_prep_df <- get_results_by_id(\n",
    "    collection = 'library_preparation_set',\n",
    "    match_id_field = 'has_input',\n",
    "    id_list = unique(biosample_df5$processed_sample_id2),\n",
    "    fields = 'id,has_input,has_output',\n",
    "    max_id = 20\n",
    ")\n",
    "\n",
    "library_prep_df <- library_prep_df %>%\n",
    "    unnest(\n",
    "        cols = c(\n",
    "            has_input,\n",
    "            has_output\n",
    "        ), names_sep = \"_\") %>%\n",
    "    distinct() %>%\n",
    "    rename(library_preparation_id = id,\n",
    "           processed_sample_id2 = has_input,\n",
    "           library_preparation_has_output = has_output)\n",
    "head(library_prep_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cb83e8-1907-4b88-9361-fa2903ec5dd0",
   "metadata": {},
   "source": [
    "Merge the library preparation data with the biosample, pooling, processed sample, extraction, and processed sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8506d2d-356d-4277-9711-052296ecfae4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'biosample_df5' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'biosample_df5' not found\nTraceback:\n",
      "1. biosample_df5 %>% left_join(library_prep_df, by = join_by(processed_sample_id2))",
      "2. left_join(., library_prep_df, by = join_by(processed_sample_id2))"
     ]
    }
   ],
   "source": [
    "biosample_df6 <- biosample_df5 %>%\n",
    "    left_join(library_prep_df, by = join_by(processed_sample_id2))\n",
    "head(biosample_df6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929a259a-2957-41c1-9f43-08d52120242f",
   "metadata": {},
   "source": [
    "# 7. Get third set of proccessed samples from the library preparation output\r",
    "\r",
    "For a third, and last time, we query the `processed_sample_set` identifier field using the `lp_has_output` identifiers. We only return the id field (as `processed_sample3`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a26bac8-0fce-4831-ba3b-46752e187140",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'biosample_df6' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'biosample_df6' not found\nTraceback:\n",
      "1. get_results_by_id(collection = \"processed_sample_set\", match_id_field = \"id\", \n .     id_list = unique(biosample_df6$library_preparation_has_output), \n .     fields = \"id\", max_id = 20)",
      "2. unique(biosample_df6$library_preparation_has_output)   # at line 9-13 of file <text>"
     ]
    }
   ],
   "source": [
    "process_set3_df <- get_results_by_id(\n",
    "    collection = 'processed_sample_set',\n",
    "    match_id_field = 'id',\n",
    "    id_list = unique(biosample_df6$library_preparation_has_output),\n",
    "    fields = 'id',\n",
    "    max_id = 20\n",
    ")\n",
    "\n",
    "process_set3_df <- process_set3_df %>%\n",
    "    rename(processed_sample_id3 = id)\n",
    "head(process_set3_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9ae081-35e2-4850-8467-e281016c46c7",
   "metadata": {},
   "source": [
    "Merge the processed sample data with the biosample, pooling, processed sample, extraction, processed sample, and library preparation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "667690ba-a598-4f72-9c21-9ff8a6c28b8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'biosample_df6' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'biosample_df6' not found\nTraceback:\n",
      "1. biosample_df6 %>% rename(processed_sample_id3 = library_preparation_has_output) %>% \n .     left_join(process_set3_df, by = join_by(processed_sample_id3))",
      "2. left_join(., process_set3_df, by = join_by(processed_sample_id3))",
      "3. rename(., processed_sample_id3 = library_preparation_has_output)"
     ]
    }
   ],
   "source": [
    "biosample_df7 <- biosample_df6 %>%\n",
    "    rename(processed_sample_id3 = library_preparation_has_output) %>%\n",
    "    left_join(process_set3_df, by = join_by(processed_sample_id3))\n",
    "head(biosample_df7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697a66f9-471e-40f0-99df-376174824fc6",
   "metadata": {},
   "source": [
    "# 8. Get omics_processing results from the processed sample identifiers\n",
    "\n",
    "Using the third batch of processed sample identifiers, we query the `omics_processing_set` on the `has_input` field. The `id` and `has_input` field names are changed to specify that they came from the `omics_processing_set`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be09a8ef-d0fb-4df8-bef3-bc8498f3d444",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'biosample_df7' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'biosample_df7' not found\nTraceback:\n",
      "1. get_results_by_id(collection = \"omics_processing_set\", match_id_field = \"has_input\", \n .     id_list = unique(biosample_df7$processed_sample_id3), fields = \"id,has_input\", \n .     max_id = 20)",
      "2. unique(biosample_df7$processed_sample_id3)   # at line 9-13 of file <text>"
     ]
    }
   ],
   "source": [
    "omics_processing_df <- get_results_by_id(\n",
    "    collection = 'omics_processing_set',\n",
    "    match_id_field = 'has_input',\n",
    "    id_list = unique(biosample_df7$processed_sample_id3),\n",
    "    fields = 'id,has_input',\n",
    "    max_id = 20\n",
    ")\n",
    "\n",
    "omics_processing_df <- omics_processing_df %>%\n",
    "    unnest(\n",
    "        cols = c(\n",
    "            has_input\n",
    "        ), names_sep = \"_\") %>%\n",
    "    rename(omics_processing_id = id,\n",
    "           processed_sample_id3 = has_input)\n",
    "head(omics_processing_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a95303-8bba-4ecf-8b9f-fd78a43ee402",
   "metadata": {},
   "source": [
    "Merge the omics processing data with the biosample, pooling, processed sample, extraction, processed sample, library preparation, and processed sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d6c028e-4260-4324-8fb3-0402216d2f7f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'biosample_df7' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'biosample_df7' not found\nTraceback:\n",
      "1. biosample_df7 %>% left_join(omics_processing_df, by = join_by(processed_sample_id3))",
      "2. left_join(., omics_processing_df, by = join_by(processed_sample_id3))"
     ]
    }
   ],
   "source": [
    "biosample_df8 <- biosample_df7 %>%\n",
    "    left_join(omics_processing_df, by = join_by(processed_sample_id3))\n",
    "head(biosample_df8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e0ec5b-b831-460a-be9f-b0e1099e266f",
   "metadata": {},
   "source": [
    "# 9. Get the metagenome_annotation_activity_set using the omics processing identifiers\n",
    "\n",
    "The `metagenome_annotation_activity_set` is queried using the identifiers obtained from the omics processing to match with the `was_informed_by` field in the `metagenome_annotation_activity_set`. Field names are clarified, once again to specify the collection they came from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24529f53-c27d-4948-824f-ad5a7a9d405c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'biosample_df8' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'biosample_df8' not found\nTraceback:\n",
      "1. get_results_by_id(collection = \"metagenome_annotation_activity_set\", \n .     match_id_field = \"was_informed_by\", id_list = unique(biosample_df8$omics_processing_id), \n .     fields = \"id,was_informed_by,has_output\", max_id = 20)",
      "2. unique(biosample_df8$omics_processing_id)   # at line 9-13 of file <text>"
     ]
    }
   ],
   "source": [
    "metagenome_annotation_df <- get_results_by_id(\n",
    "    collection = 'metagenome_annotation_activity_set',\n",
    "    match_id_field = 'was_informed_by',\n",
    "    id_list = unique(biosample_df8$omics_processing_id),\n",
    "    fields = 'id,was_informed_by,has_output',\n",
    "    max_id = 20\n",
    ")\n",
    "\n",
    "metagenome_annotation_df <- metagenome_annotation_df %>%\n",
    "    unnest(\n",
    "        cols = c(\n",
    "            was_informed_by,\n",
    "            has_output\n",
    "        ), names_sep = \"_\") %>%\n",
    "    rename(metagenome_annotation_id = id,\n",
    "           omics_processing_id = was_informed_by,\n",
    "           matagenome_annotation_has_output = has_output)\n",
    "head(metagenome_annotation_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e67c4b5-4c92-4331-9072-9a65d7ae52bd",
   "metadata": {},
   "source": [
    "Merge the metagenome annotation data with the biosample, pooling, processed sample, extraction, processed sample, library preparation, processed sample, omics processing, and processed sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9aa89e83-67de-4620-ba98-a15311882551",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'biosample_df8' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'biosample_df8' not found\nTraceback:\n",
      "1. biosample_df8 %>% left_join(metagenome_annotation_df, by = join_by(omics_processing_id))",
      "2. left_join(., metagenome_annotation_df, by = join_by(omics_processing_id))"
     ]
    }
   ],
   "source": [
    "biosample_df9 <- biosample_df8 %>%\n",
    "    left_join(metagenome_annotation_df, by = join_by(omics_processing_id))\n",
    "head(biosample_df9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814da9fb-b162-485e-b319-ee47e81920fc",
   "metadata": {},
   "source": [
    "# 10. Get data objects from the metagenome activity result outputs\r",
    "\r",
    "We query the `data_object_set` using the `matagenome_annotation_has_output` identifiers to match the `id` field in the data objects. We then filter the results for only those results with a `data_object_type` of `Scaffold Lineage tsv` (since this has contig taxonomy results). Note that the `url` is a new field returned that contains the tsvs we will need for the final analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf1f3a9c-ba08-43a6-b9aa-577ec7586969",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'biosample_df9' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'biosample_df9' not found\nTraceback:\n",
      "1. get_results_by_id(collection = \"data_object_set\", match_id_field = \"id\", \n .     id_list = unique(biosample_df9$matagenome_annotation_has_output), \n .     fields = \"id,data_object_type,url\", max_id = 50)",
      "2. unique(biosample_df9$matagenome_annotation_has_output)   # at line 9-13 of file <text>"
     ]
    }
   ],
   "source": [
    "data_object_df <- get_results_by_id(\n",
    "    collection = 'data_object_set',\n",
    "    match_id_field = 'id',\n",
    "    id_list = unique(biosample_df9$matagenome_annotation_has_output),\n",
    "    fields = 'id,data_object_type,url',\n",
    "    max_id = 50\n",
    ")\n",
    "\n",
    "# Filter the data object results to only include the Scaffold Lineage tsv files\n",
    "data_object_df <- data_object_df %>%\n",
    "    rename(data_object_id = id) %>%\n",
    "    filter(data_object_type == 'Scaffold Lineage tsv')\n",
    "head(data_object_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2825237d-c5ad-4777-9db9-b4e7e5c68b6c",
   "metadata": {},
   "source": [
    "Merge the data object data with the biosample, pooling, processed sample, extraction, processed sample, library preparation, processed sample, omics processing, processed sample, and metagenome annotation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3ac4d7e-861f-4553-b05c-751ae08d2304",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'biosample_df9' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'biosample_df9' not found\nTraceback:\n",
      "1. biosample_df9 %>% rename(data_object_id = matagenome_annotation_has_output) %>% \n .     left_join(data_object_df, by = join_by(data_object_id))",
      "2. left_join(., data_object_df, by = join_by(data_object_id))",
      "3. rename(., data_object_id = matagenome_annotation_has_output)"
     ]
    }
   ],
   "source": [
    "biosample_df10 <- biosample_df9 %>%\n",
    "    rename(data_object_id = matagenome_annotation_has_output) %>%\n",
    "    left_join(data_object_df, by = join_by(data_object_id))\n",
    "head(biosample_df10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56eedef-1f56-451d-99f6-9940ed6ba44e",
   "metadata": {},
   "source": [
    "## Clean up the combined results\n",
    "\n",
    "In the final step of retrieving and cleaning the data, we clean up the final merged data frame by removing all of the \"joining columns\" that are not needed in our final analysis. Because some of the biosamples were pooled, we only retain unique url results (and drop the `biosample_id` column). The only columns we retain are the `soil_horizon`, `geo_loc_name`, and the `url` to the tsv. The `final_df` is displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9444e91a-1305-4a15-ae8d-338ca54eb5e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'biosample_df10' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'biosample_df10' not found\nTraceback:\n",
      "1. biosample_df10 %>% select(biosample_id, soil_horizon, geo_loc_name, \n .     data_object_id, data_object_type, url) %>% distinct() %>% \n .     filter(!is.na(url))",
      "2. filter(., !is.na(url))",
      "3. distinct(.)",
      "4. select(., biosample_id, soil_horizon, geo_loc_name, data_object_id, \n .     data_object_type, url)"
     ]
    }
   ],
   "source": [
    "biosample_df_final <- biosample_df10 %>%\n",
    "    select(biosample_id, soil_horizon, geo_loc_name, data_object_id, data_object_type, url) %>%\n",
    "    distinct() %>%\n",
    "    filter(!is.na(url))\n",
    "head(biosample_df_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8706411-d4ac-45df-b443-ae113d98421e",
   "metadata": {},
   "source": [
    "## Show how many results have M horizon vs. O horizon\n",
    "\n",
    "The `soil_horizon` column can be counted using the `count()` functionality. There are many more M horizon samples than O horizon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7521a8c4-7b02-4d4b-a0c4-4287bc814516",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'biosample_df_final' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'biosample_df_final' not found\nTraceback:\n",
      "1. biosample_df_final %>% count(soil_horizon)",
      "2. count(., soil_horizon)"
     ]
    }
   ],
   "source": [
    "biosample_df_final %>%\n",
    "    count(soil_horizon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cfdca2-5d15-4f40-96e9-5a0454ac2d56",
   "metadata": {},
   "source": [
    "## Example of what the TSV contig taxa file looks like\n",
    "\n",
    "A snippet of the TSV file we need to iterate over to get the taxa abundance for the contigs is shown below. The third column is the initial count for the taxa, where each row is `1.0`. However, there are duplicate rows of taxa, meaning there are actually more than `1.0` for several taxa (though they appear as duplicate rows with `1.0` as the count`). We will take this into consideration when we calculate the relative abundance for each taxa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16c7457f-c1dc-4344-8049-581eee81ffd2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'biosample_df_final' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'biosample_df_final' not found\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "url <- biosample_df_final$url[1]\n",
    "\n",
    "# Read the TSV file\n",
    "contig_taxa_df <- read_tsv(url, col_names = FALSE)\n",
    "\n",
    "# Add column names \n",
    "colnames(contig_taxa_df) <- c('contig_id', 'taxa', 'initial_count')\n",
    "\n",
    "# Show the first few rows\n",
    "head(contig_taxa_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484d4ab1-bdf9-4d60-898f-e178daea0c42",
   "metadata": {},
   "source": [
    "## Iterate throught the TSVs to get the contig taxa information\n",
    "\n",
    "Using the readr's `read_tsv` function, the TSV urls can be iterated over gathering the taxa information. The TSVs are converted into dataframes where they are manipulated to suit the data structure needed. The columns are given names and the taxa column is split into a proper list (instead of a string of items separated by a semicolon ;). The third element from the list of taxa is retrieved to get only the phylum level information of the taxa (or unknown to the highest available taxon). A grouping function is performed on the `taxa` column and the `count()` functionality is used to calculate the count for how many times each taxa occurs, which is then used to calculate the relative abundance of each taxa for each sample. \n",
    "\n",
    "Any errors in requesting the TSV urls are collected as a dictionary, so we can either try to query them again, or look into why they were not able to be collected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a331e72-182c-4a55-b1e9-705908b6238d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'biosample_df_final' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'biosample_df_final' not found\nTraceback:\n",
      "1. unique(biosample_df_final$url)"
     ]
    }
   ],
   "source": [
    "urls <- unique(biosample_df_final$url)\n",
    "results_list <- c()\n",
    "error_dict <- list()\n",
    "\n",
    "for (i in 1:length(urls)) {\n",
    "    # if i a factor of 100, print the progress\n",
    "    if (i %% 10 == 0) {\n",
    "        print(paste('Processing', i, 'of', length(urls)))\n",
    "    }\n",
    "    url <- urls[i]\n",
    "    tryCatch({\n",
    "        contig_taxa_df <- read_tsv(url, col_names = FALSE, show_col_types = FALSE)\n",
    "        colnames(contig_taxa_df) <- c('contig_id', 'taxa', 'initial_count')\n",
    "        \n",
    "        # Clean up the taxa column and deal with unknown taxa\n",
    "        contig_taxa_df$taxa_new <- contig_taxa_df$taxa\n",
    "        contig_taxa_df$taxa_new <- sapply(strsplit(contig_taxa_df$taxa_new, ';'), function(x) x[3])\n",
    "        contig_taxa_df$taxa_new <- ifelse(\n",
    "            is.na(contig_taxa_df$taxa_new), \n",
    "            paste('Unknown', sapply(strsplit(contig_taxa_df$taxa, ';'), function(x) x[2])), \n",
    "            contig_taxa_df$taxa_new)\n",
    "        contig_taxa_df$taxa_new <- ifelse(\n",
    "            contig_taxa_df$taxa_new == \"Unknown NA\", \n",
    "            paste('Unknown', sapply(strsplit(contig_taxa_df$taxa, ';'), function(x) x[1])), \n",
    "            contig_taxa_df$taxa_new)\n",
    "        contig_taxa_df$taxa <- contig_taxa_df$taxa_new\n",
    "\n",
    "        contig_taxa_df <- contig_taxa_df %>%\n",
    "            group_by(taxa) %>%\n",
    "            summarise(count = n()) %>%\n",
    "            mutate(relative_abundance = count / sum(count))\n",
    "        contig_taxa_df$url <- url\n",
    "        results_list[[i]] <- contig_taxa_df\n",
    "        results_list[[i]] <- contig_taxa_df\n",
    "\n",
    "    }, error = function(e) {\n",
    "        error_dict[[i]] <- e\n",
    "    })\n",
    "}\n",
    "\n",
    "contig_df <- bind_rows(results_list) \n",
    "\n",
    "head(contig_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f425cddd-6a17-4ebb-bf0d-415df07f28ad",
   "metadata": {},
   "source": [
    "## Clean up the relative abundance data to fill in NAs with 0 for unobserved taxa\r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dae25f8c-ffb9-43a7-8b9b-9464d3e9b8b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'biosample_df_final' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'biosample_df_final' not found\nTraceback:\n",
      "1. biosample_df_final %>% select(soil_horizon, geo_loc_name, url) %>% \n .     distinct() %>% right_join(contig_df, by = join_by(url))",
      "2. right_join(., contig_df, by = join_by(url))",
      "3. distinct(.)",
      "4. select(., soil_horizon, geo_loc_name, url)"
     ]
    }
   ],
   "source": [
    "# First merge to get the url for geo_loc_name and soil_horizon\n",
    "biosample_taxa_df <- biosample_df_final %>%\n",
    "    select(soil_horizon, geo_loc_name, url) %>%\n",
    "    distinct() %>%\n",
    "    right_join(contig_df, by = join_by(url))\n",
    "\n",
    "# Then pivot the table to fill in the relative abundance as zero for un-observed taxa\n",
    "biosample_taxa_df_wide <- biosample_taxa_df %>%\n",
    "    pivot_wider(id_cols = c(url, soil_horizon, geo_loc_name),\n",
    "        names_from = taxa, values_from = relative_abundance) %>%\n",
    "    replace(is.na(.), 0)\n",
    "\n",
    "# And unpivot the table to get the taxa relative abundance for each biosample\n",
    "biosample_taxa_df <- biosample_taxa_df_wide %>%\n",
    "    pivot_longer(cols = -c(url, soil_horizon, geo_loc_name), names_to = 'taxa', values_to = 'relative_abundance')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b143ea72-6869-4d82-987b-8b7281fb3806",
   "metadata": {},
   "source": [
    "## Plot the average taxa abundance for all M and O horizon soil samples\r",
    "First calculate the average relative abundance for each taxa in each soil horizon.  Next, we'll pull out the top ten taxa and lump all others into an \"Other\" category for plotting purposes using the `forcats::fct_other` function.  Then we'll calculate the mean relative abundance of each taxa for each soil horizon. Finally, we'll choose an appropriate color palette for the plot, and plot the relative abundance of each taxa for each soil horizon at each location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "460474ef-2d2e-4553-85fc-78dc5a756bf1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'biosample_taxa_df' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'biosample_taxa_df' not found\nTraceback:\n",
      "1. biosample_taxa_df %>% group_by(soil_horizon, taxa) %>% summarise(mean_relative_abundance = mean(relative_abundance)) %>% \n .     arrange(mean_relative_abundance) %>% mutate(taxa = factor(taxa, \n .     levels = rev(unique(taxa)))) %>% mutate(taxa_lump = forcats::fct_other(taxa, \n .     keep = levels(taxa)[1:15], other_level = \"Other\"))",
      "2. mutate(., taxa_lump = forcats::fct_other(taxa, keep = levels(taxa)[1:15], \n .     other_level = \"Other\"))",
      "3. mutate(., taxa = factor(taxa, levels = rev(unique(taxa))))",
      "4. arrange(., mean_relative_abundance)",
      "5. summarise(., mean_relative_abundance = mean(relative_abundance))",
      "6. group_by(., soil_horizon, taxa)"
     ]
    }
   ],
   "source": [
    "horizon_taxa <- biosample_taxa_df %>%\n",
    "    group_by(soil_horizon, taxa) %>%\n",
    "    summarise(mean_relative_abundance = mean(relative_abundance))%>%\n",
    "    arrange(mean_relative_abundance) %>%\n",
    "    mutate(taxa = factor(taxa, levels = rev(unique(taxa)))) %>%\n",
    "    mutate(taxa_lump = forcats::fct_other(taxa, keep = levels(taxa)[1:15], other_level = 'Other')) \n",
    "           \n",
    "# Make color palette that is 9 colors long, and followed with grey\n",
    "color_pal <- c(RColorBrewer::brewer.pal(8, 'Set1'), RColorBrewer::brewer.pal(7, 'Set3'), 'grey')\n",
    "g <- ggplot(horizon_taxa, aes(x = soil_horizon, y = mean_relative_abundance, fill = taxa_lump)) +\n",
    "    geom_bar(stat = 'identity', color = NA) +\n",
    "    theme(axis.text.x = element_text(angle = 90, hjust = 1)) +\n",
    "    labs(title = 'Taxa abundance of M and O horizon soil samples for each location',\n",
    "         x = 'Soil Horizon', y = 'Mean relative abundance', fill = NULL) +\n",
    "    scale_fill_manual(values = color_pal) +\n",
    "    theme_minimal() \n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12922925-eabe-436c-ab87-37fbb734ca88",
   "metadata": {},
   "source": [
    "## Plot the taxa abundance of M and O horizon soil samples for each location\n",
    "First we'll pull out the top ten taxa and lump all others into an \"Other\" category for plotting purposes using the `forcats::fct_other` function.  Then we'll calculate the mean relative abundance of each taxa for each soil horizon for each location. Finally, we'll plot the relative abundance of each taxa for each soil horizon at each location (using the same color palette as above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "af8211c8-93cd-4be7-8fc5-1bbcc30187ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'biosample_taxa_df' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'biosample_taxa_df' not found\nTraceback:\n",
      "1. biosample_taxa_df %>% group_by(geo_loc_name, soil_horizon, taxa) %>% \n .     summarise(mean_relative_abundance = mean(relative_abundance)) %>% \n .     arrange(mean_relative_abundance) %>% mutate(taxa = factor(taxa, \n .     levels = rev(unique(taxa)))) %>% mutate(taxa_lump = forcats::fct_other(taxa, \n .     keep = levels(taxa)[1:15], other_level = \"Other\")) %>% mutate(soil_horizon = factor(soil_horizon, \n .     levels = c(\"M horizon\", \"O horizon\"), labels = c(\"M\", \"O\")))",
      "2. mutate(., soil_horizon = factor(soil_horizon, levels = c(\"M horizon\", \n .     \"O horizon\"), labels = c(\"M\", \"O\")))",
      "3. mutate(., taxa_lump = forcats::fct_other(taxa, keep = levels(taxa)[1:15], \n .     other_level = \"Other\"))",
      "4. mutate(., taxa = factor(taxa, levels = rev(unique(taxa))))",
      "5. arrange(., mean_relative_abundance)",
      "6. summarise(., mean_relative_abundance = mean(relative_abundance))",
      "7. group_by(., geo_loc_name, soil_horizon, taxa)"
     ]
    }
   ],
   "source": [
    "geo_taxa <- biosample_taxa_df %>%\n",
    "    group_by(geo_loc_name, soil_horizon, taxa) %>%\n",
    "    summarise(mean_relative_abundance = mean(relative_abundance)) %>%\n",
    "    arrange(mean_relative_abundance) %>%\n",
    "    mutate(taxa = factor(taxa, levels = rev(unique(taxa)))) %>%\n",
    "    mutate(taxa_lump = forcats::fct_other(taxa, keep = levels(taxa)[1:15], other_level = 'Other')) %>%\n",
    "    mutate(soil_horizon = factor(soil_horizon, levels = c('M horizon', 'O horizon'), labels = c('M', 'O')))\n",
    "\n",
    "g <- ggplot(geo_taxa, aes(x = soil_horizon, y = mean_relative_abundance, fill = taxa_lump)) +\n",
    "    geom_bar(stat = 'identity', color = NA) +\n",
    "    facet_wrap(~geo_loc_name, nrow = 1,labeller =  label_wrap_gen(width = 20, multi_line = TRUE)) +\n",
    "    labs(title = 'Taxa abundance of M and O horizon soil samples for each location',\n",
    "         x = 'Soil Horizon', y = 'Mean relative abundance', fill = NULL) +\n",
    "    scale_fill_manual(values = color_pal) +\n",
    "    theme_minimal()+\n",
    "    theme(axis.text.x = element_text(angle = 90, hjust = 1),\n",
    "          legend.position = \"bottom\") \n",
    "g"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
