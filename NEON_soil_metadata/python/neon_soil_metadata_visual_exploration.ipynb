{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c44cb7dc-fc42-4c03-90f7-347d120eedb7",
   "metadata": {},
   "source": [
    "# Data exploration and visualization for the soil metagenomes (DP1.10107.001) NEON study  \n",
    "\n",
    "This notebook explores how soil pH changes with time for the 47 sites part of the NEON study. It also examines how the average water_content changes by season for each site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e8319d-fabe-4bb7-9dbf-20614573a5ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "import pandas as pd\n",
    "import folium\n",
    "import altair as alt\n",
    "from altair import Chart\n",
    "from datetime import datetime\n",
    "\n",
    "import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a48c09e-cd0d-41ea-bfa6-63ebf65518c3",
   "metadata": {},
   "source": [
    "### Get the Study ID for the NEON soil metagenome DP1.10107.001 project\n",
    "\n",
    "Using the python requests library, and the [NMDC studies find endpoint](https://api.microbiomedata.org/docs#/find/find_studies_studies_get), we can get the NMDC study ID to filter by. More information regarding the API can be found [here](https://github.com/microbiomedata/NMDC_documentation/blob/main/docs/howto_guides/api_gui.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a8e74a-f07e-4cbf-8fe4-3ed833340118",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_url = \"https://api.microbiomedata.org\"\n",
    "filt = \"name.search:DP1.10107.001\"\n",
    "url = f\"{base_url}/studies?filter={filt}\"\n",
    "resp = requests.get(url)\n",
    "studies = resp.json()[\"results\"]\n",
    "study_id = []\n",
    "for study in studies:\n",
    "    study_id.append(study[\"id\"])\n",
    "# Since there is only one value in the results, convert list to a string\n",
    "study = \"\".join(study_id)\n",
    "print(f\"{study =}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf83ee46-1b1b-4db4-946b-975f07f9563b",
   "metadata": {},
   "source": [
    "### Get all the biosamples associated with the NEON soil metagenomes study by the NMDC study ID\n",
    "\n",
    "We can use the NMDC study ID obtained above, and the [NMDC biosamples find endpoint](https://api.microbiomedata.org/docs#/find/find_biosamples_biosamples_get) to filter the biosamples in the data portal by the study they are `part_of`. We can limit the results by the fields we would like returned, such as `ph`, `water_content`, etc. Cursor pagination is used to request a large amount of information - only 2000 results `per_page` are allowed. Here the total number of biosamples associated with the NEON study is printed. A list of all the results (`all_results`) is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218f7a63-e63b-46c1-902e-c44d456b69b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify the number of results per_page, the desired fields to be returned, the filter method, and cursor pagination\n",
    "per_page = 2000\n",
    "fields = \"ph,collection_date.has_raw_value,env_medium,geo_loc_name,lat_lon,water_content,soil_horizon,elev\"\n",
    "filt = f\"part_of:{study}\"\n",
    "cursor = \"*\"\n",
    "all_results = []\n",
    "\n",
    "\n",
    "# Use cursor pagination to get results\n",
    "while True:\n",
    "    url = f\"{base_url}/biosamples?filter={filt}&per_page={per_page}&cursor={cursor}&fields={fields}\"\n",
    "    resp = requests.get(url)\n",
    "    data = resp.json()\n",
    "    results = data[\"results\"]\n",
    "    cursor = data[\"meta\"][\"next_cursor\"]\n",
    "    all_results.extend(results)\n",
    "    if not cursor:\n",
    "        break\n",
    "\n",
    "print(f\"Total number of biosamples: {len(all_results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655675f9-a8cf-40cb-9527-b2934bfed58b",
   "metadata": {},
   "source": [
    "### Geo-location and collection date exploration\n",
    "\n",
    "Using the returned results, we can explore the number of locations, or sites, in the data using the `geo_location` field (aka slot) and the `lat_lon` field, as well as the number of collection dates using the `collection_date` field. Here, we print the number of distinct coordinates, geo_locations, and dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fc796f-8616-41ca-8689-e8f60add4f2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find total number of NEON coordinates\n",
    "# Find the total number of geo locations (equivalent to NEON sites)\n",
    "# Find the total  number of collection dates\n",
    "\n",
    "# Initialize empty sets for coordinates, geo locations, and dates\n",
    "coordinates = set()\n",
    "geo_locs = set()\n",
    "dates = set()\n",
    "\n",
    "# Initialize a dictionary to log IDs of samps missing certain data\n",
    "missing_data_log = {\n",
    "    'missing_lat_lon': [],\n",
    "    'missing_geo_loc_name': [],\n",
    "}\n",
    "\n",
    "for samp in all_results:\n",
    "    samp_id = samp.get('id', 'Unknown ID')  # Assuming each samp has an 'id' key\n",
    "    \n",
    "    # Check and log if 'lat_lon' data is missing\n",
    "    try:\n",
    "        lat_lon = f\"{samp['lat_lon']['latitude']},{samp['lat_lon']['longitude']}\"\n",
    "        coordinates.add(lat_lon)\n",
    "    except KeyError:\n",
    "        missing_data_log['missing_lat_lon'].append(samp_id)\n",
    "    \n",
    "    # Check and log if 'geo_loc_name' data is missing\n",
    "    try:\n",
    "        geo_loc = samp[\"geo_loc_name\"][\"has_raw_value\"]\n",
    "        geo_locs.add(geo_loc)\n",
    "    except KeyError:\n",
    "        missing_data_log['missing_geo_loc_name'].append(samp_id)\n",
    "    \n",
    "    # Proceed with collection date as usual\n",
    "    try:\n",
    "        collection_date = samp[\"collection_date\"][\"has_raw_value\"]\n",
    "        dates.add(collection_date)\n",
    "    except KeyError:\n",
    "        pass  # Assuming you're not logging missing dates based on your previous instructions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(f\"Number of NEON coordinates: {len(coordinates)}\")\n",
    "print(f\"Number of geo locations (sites): {len(geo_locs)}\")\n",
    "print(f\"Number of dates: {len(dates)}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f0f0706e311f86f",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Print the missing data log"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46681ed550b3e374"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pprint.pprint(missing_data_log)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ebaa4f9ae80e14ff",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "96fb204f-8960-453d-93a8-226cf8bd8511",
   "metadata": {},
   "source": [
    "### Print a returned result\n",
    "\n",
    "Let's print the first returned result to see what the requested data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a70709a-922d-4391-9a50-6e2f326aae1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pprint.pprint(all_results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a488535-2ecb-4f8b-a000-0d64d436652f",
   "metadata": {},
   "source": [
    "### Convert results to a data frame and transform into desired format\n",
    "We can use the pandas python library to convert the requested results into a data frame. By looping through the results, we can update the data types for the fields (e.g. convert `collection_date` to a date using the datetime library and drop the times) and create a dictionary where the keys are the columns and the values are the results we are looping through, appending the dictionary to an initially empty list (`df_inp`). This allows for easy conversion to a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd34f79b-4060-4c8f-8eaa-bbb5c4ae1fd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert results to dataframes\n",
    "# Transform results to desired format and convert to a data frame\n",
    "df_inp = []\n",
    "water_content_units = \"g of water/g of dry soil\"\n",
    "\n",
    "for biosamp in all_results:\n",
    "    # Reset variables\n",
    "    water_content = None\n",
    "    ph = None\n",
    "\n",
    "    # Initialize record with default values\n",
    "    rec = {\n",
    "        \"id\": biosamp.get(\"id\"),\n",
    "        \"collection_date\": None,\n",
    "        \"soil_horizon\": biosamp.get(\"soil_horizon\"),\n",
    "        \"water_content\": water_content,\n",
    "        \"ph\": ph,\n",
    "        \"elev\": None,\n",
    "        \"location\": None,\n",
    "        \"latitude\": None,\n",
    "        \"longitude\": None,\n",
    "    }\n",
    "\n",
    "    # Get only month, day, and year from collection_date (remove times)\n",
    "    try:\n",
    "        date_str = biosamp[\"collection_date\"][\"has_raw_value\"]\n",
    "        date = datetime.strptime(date_str, \"%Y-%m-%dT%H:%MZ\")\n",
    "        rec[\"collection_date\"] = date.strftime(\"%Y-%m-%d\")\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "    # Extract out units of water_content and convert to float\n",
    "    # Handle water_content when it's a list\n",
    "    try:\n",
    "        if 'water_content' in biosamp:\n",
    "            # Assuming the list contains strings and we're looking for the first element\n",
    "            water_content_list = biosamp[\"water_content\"]\n",
    "            if water_content_list:\n",
    "                # Convert the first list element to string and remove units\n",
    "                water_content_str = water_content_list[0].replace(\"g of water/g of dry soil\", \"\").strip()\n",
    "                rec[\"water_content\"] = float(water_content_str)\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "    # Convert pH to float, if present\n",
    "    rec[\"ph\"] = float(biosamp[\"ph\"]) if \"ph\" in biosamp else None\n",
    "\n",
    "    # Extract elevation, location, and lat_lon\n",
    "    try:\n",
    "        rec[\"elev\"] = float(biosamp[\"elev\"])\n",
    "    except (KeyError, ValueError):\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        rec[\"location\"] = biosamp[\"geo_loc_name\"][\"has_raw_value\"]\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        rec[\"latitude\"] = biosamp[\"lat_lon\"][\"latitude\"]\n",
    "        rec[\"longitude\"] = biosamp[\"lat_lon\"][\"longitude\"]\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "    df_inp.append(rec)\n",
    "\n",
    "df = pd.DataFrame(df_inp)\n",
    "\n",
    "df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f88193-1f3c-4ae2-809a-dae21224956c",
   "metadata": {},
   "source": [
    "### Find min/max and mid coordinates of the latitude and longitude coordinates\n",
    "\n",
    "In order to create a map of the NEON sites, we will need to know the minimum and maximum latitude and longitude coordinates. We can calculate the midpoint by defining a function called `find_square_midpoint` and calling the function using the min/max coordinates. The mid-coordinates will allow us to set a middle point in our map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1d1743-9d5f-4aad-a529-c4d66f12edc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find middle coordinates to inform map center\n",
    "min_lat = df[\"latitude\"].min()\n",
    "max_lat = df[\"latitude\"].max()\n",
    "\n",
    "min_lon = df[\"longitude\"].min()\n",
    "max_lon = df[\"longitude\"].max()\n",
    "\n",
    "def find_square_midpoint(min_lat, max_lon, max_lat, min_lon):\n",
    "    # calculate midpoint latitude\n",
    "    mid_lat = (min_lat + max_lat) / 2\n",
    "    \n",
    "    # calculate midpoint longitude\n",
    "    if abs(max_lon - min_lon) <= 180:\n",
    "        mid_lon = (min_lon + max_lon) / 2\n",
    "    else:\n",
    "        # If the line crosses the 180 degree meridian, adjust the midpoint longitude\n",
    "        mid_lon = ((max_lon + min_lon + 360) % 360) / 2 - 180\n",
    "   \n",
    "    return int(round(mid_lat, 0)), int(round(mid_lon, 0))\n",
    "\n",
    "mid_coords = find_square_midpoint(min_lat, max_lon, max_lat, min_lon)\n",
    "print(f\"min latitude: {min_lat}\")\n",
    "print(f\"max latitude: {max_lat}\")\n",
    "print(f\"min longitude: {min_lon}\")\n",
    "print(f\"max longitude: {max_lon}\")\n",
    "\n",
    "print(f\"midpoint coordintates: {mid_coords}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e4d1dc-d071-4878-b98a-aced74b50a3f",
   "metadata": {},
   "source": [
    "### Create an interactive map of the NEON sites with scatter plots of ph vs. time\n",
    "\n",
    "Using the folium python library to create a map and the altair library to create charts of pH vs. time, we can create a clickable map of the NEON sites that show the pH visualizations. We will have to loop through the NEON sites by grouping our data frame by location and creating a chart of each location within the loop. Note that the mean latitude and longitude for each site were chosen as the map marker coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe7ebd7-0b17-46f5-9850-e3febbfec5c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create map of NEON sites \n",
    "m = folium.Map(\n",
    "    tiles=\"https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}\",\n",
    "    attr=\"Tiles &copy; Esri &mdash; Source: Esri, i-cubed, USDA, USGS, AEX, GeoEye, Getmapping, Aerogrid, IGN, IGP, UPR-EGP, and the GIS User Community\",\n",
    "    location=(mid_coords),\n",
    "    zoom_start=3,\n",
    "    control_scale=True)\n",
    "\n",
    "# group data frames by site (e.g. location)\n",
    "grouped = df.groupby(\"location\")\n",
    "result_dfs = {}\n",
    "for name, group_df in grouped:\n",
    "    result_dfs[name] = group_df.reset_index(drop=True)\n",
    "\n",
    "# Add markers to map based on location name (site) - used the mean coordinates for each site \n",
    "for name, site_df in result_dfs.items():\n",
    "    mean_lat = site_df[\"latitude\"].mean()\n",
    "    mean_lon = site_df[\"longitude\"].mean()\n",
    "\n",
    "    # Create scatter plot of pH vs. time and add a linear regression\n",
    "    scatter = Chart(site_df).mark_circle().encode(x=\"collection_date\", y=\"ph\", color=\"soil_horizon:N\")\n",
    "    chart = scatter.properties(width=600, height=400, title=f'{name}: Change in soil pH over time')\n",
    "\n",
    "    # Add charts as popup for each NEON site on the map\n",
    "    vega_lite = folium.VegaLite(chart, width=\"100%\", height=\"100%\")\n",
    "    marker = folium.Marker(\n",
    "        location=[mean_lat, mean_lon],\n",
    "        tooltip=\"click me!\")\n",
    "    popup = folium.Popup()\n",
    "    vega_lite.add_to(popup)\n",
    "    popup.add_to(marker)\n",
    "    marker.add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0debe93-042d-4918-9784-23106a6eec5c",
   "metadata": {},
   "source": [
    "### Bar chart of the average water_content of each site and the season\n",
    "\n",
    "To look at how the water_content of each NEON site changes with the seasons, we can add a column to the data frame for the month and create a function that adds a column for the season based on the number of the month. Finally, using the altair library we can aggregate the water_content for each location using the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18832546-a0f8-45ad-8a6e-d700fc6c9158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does the average water_content change with the seasons per site?\n",
    "df[\"collection_date\"] = pd.to_datetime(df[\"collection_date\"])\n",
    "\n",
    "df[\"month\"] = df[\"collection_date\"].dt.month\n",
    "\n",
    "def get_season(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return \"Winter\"\n",
    "    elif month in [3, 4, 5]:\n",
    "        return \"Spring\"\n",
    "    elif month in [6, 7, 8]:\n",
    "        return \"Summer\"\n",
    "    else:\n",
    "        return \"Fall\"\n",
    "\n",
    "df[\"season\"] = df[\"month\"].apply(get_season)\n",
    "\n",
    "bar = Chart(df).mark_bar().encode(x=\"location\", y=alt.Y('mean(water_content)', title=f\"water_content in {water_content_units}\"),color=\"season\")\n",
    "chart = bar.properties(width=600, height=400, title=f'Change in average water_content of NEON sites by season')\n",
    "chart"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "## Pure matplotlib alternative"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78b9c9981ff524bf",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Ensure 'collection_date' is in datetime format\n",
    "df[\"collection_date\"] = pd.to_datetime(df[\"collection_date\"])\n",
    "df[\"month\"] = df[\"collection_date\"].dt.month\n",
    "\n",
    "def get_season(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return \"Winter\"\n",
    "    elif month in [3, 4, 5]:\n",
    "        return \"Spring\"\n",
    "    elif month in [6, 7, 8]:\n",
    "        return \"Summer\"\n",
    "    else:\n",
    "        return \"Fall\"\n",
    "\n",
    "df[\"season\"] = df[\"month\"].apply(get_season)\n",
    "\n",
    "# Group by location and season, then calculate mean water_content\n",
    "grouped = df.groupby(['location', 'season'])['water_content'].mean().unstack(fill_value=0)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(12, 8))  # Adjusted for a taller plot\n",
    "\n",
    "# Locations for the bars on the x-axis\n",
    "ind = np.arange(len(grouped))\n",
    "\n",
    "# Bottom for the stacking\n",
    "bottom = np.zeros(len(grouped))\n",
    "\n",
    "seasons = grouped.columns\n",
    "colors = ['skyblue', 'orange', 'lightgreen', 'pink']  # Colors for each season\n",
    "for season, color in zip(seasons, colors):\n",
    "    ax.bar(ind, grouped[season], bottom=bottom, label=season, color=color)\n",
    "    bottom += grouped[season]\n",
    "\n",
    "# Modify x-axis labels to only include text after the last comma\n",
    "# Split each index by comma, take the last part, and join back into a string if needed\n",
    "new_labels = [label.split(',')[-1].strip() for label in grouped.index]\n",
    "\n",
    "ax.set_title('Change in Average Water Content by Season and Location')\n",
    "ax.set_xticks(ind)\n",
    "ax.set_xticklabels(new_labels, rotation=45, ha=\"right\")\n",
    "ax.set_ylabel('Average Water Content (g of water/g of dry soil)')\n",
    "ax.set_xlabel('Location')\n",
    "\n",
    "ax.legend(title='Season')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b94e2eb97d48c513",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "228aad7faa1b3408",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
