name: (dev) Execute python notebooks

on:
  pull_request:
  workflow_dispatch:
  schedule:
    - cron: "0 0 * * 0"
  push:
    branches:
      - main

jobs:
  setup:
    runs-on: ubuntu-latest
    outputs:
      notebooks: ${{ steps.set-notebooks.outputs.notebooks }}
    steps:
    - id: checkout
      uses: actions/checkout@v3

    - id: python-setup
      name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.11'

    - id: python-dependencies
      name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install jupyter

    # Cache the installed dependencies for parallel jobs
    - name: Cache Python dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - id: set-notebooks
      name: Set notebook matrix
      run: |
        echo 'notebooks=[{"name": "bioscales", "path": "bioscales_biogeochemical_metadata/python/bioscales.ipynb"}, {"name": "NOM", "path": "NOM_visualizations/python/nom_data.ipynb"}]' >> $GITHUB_OUTPUT

  execute-notebooks-dev:
    runs-on: ubuntu-latest
    needs: setup
    continue-on-error: true  # Allow all notebooks to run even if one fails
    strategy:
      fail-fast: false
      matrix:
        notebook: ${{ fromJson(needs.setup.outputs.notebooks) }}
      
    steps:
    - id: checkout
      uses: actions/checkout@v3

    - id: python-setup
      name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.11'

    - name: Restore Python dependencies cache
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - id: python-dependencies
      name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install jupyter

    - id: execute
      name: (dev) Execute ${{ matrix.notebook.name }} notebook
      run: |
        echo "Executing notebook: ${{ matrix.notebook.path }}"
        jupyter nbconvert --execute --to notebook --inplace "${{ matrix.notebook.path }}"

        if [ $? -ne 0 ]; then
          echo "Notebook ${{ matrix.notebook.name }} failed."
          echo "FAILED" > results-${{ matrix.notebook.name }}.txt
        else
          echo "SUCCESS" > results-${{ matrix.notebook.name }}.txt
        fi

    - name: Upload results
      uses: actions/upload-artifact@v4
      with:
        name: notebook-results-${{ matrix.notebook.name }}
        path: results-${{ matrix.notebook.name }}.txt

  post-check:
    runs-on: ubuntu-latest
    needs: [setup, execute-notebooks-dev]
    if: always()  # Ensure this step runs even if notebooks fail
    steps:
    - name: Gather all notebook results
      uses: actions/download-artifact@v4
      with:
        path: results/

    - id: check-results
      name: Validate notebook execution
      run: |
        EXPECTED_NOTEBOOKS='${{ needs.setup.outputs.notebooks }}'

        echo "Expected notebooks JSON: $EXPECTED_NOTEBOOKS"

        # Check if we got the expected notebooks JSON
        if [ -z "$EXPECTED_NOTEBOOKS" ] || [ "$EXPECTED_NOTEBOOKS" = "null" ]; then
          echo "::error::Failed to get expected notebooks from setup job"
          exit 1
        fi

        touch errors.log

        # Validate that all expected artifacts exist and check their content
        for notebook in $(jq -r '.[] | .name' expected_notebooks.json); do
          # The artifact structure is: results/notebook-results-{name}/results-{name}.txt
          ARTIFACT_DIR="results/notebook-results-${notebook}"
          ARTIFACT_FILE="${ARTIFACT_DIR}/results-${notebook}.txt"
          
          echo "Checking for artifact: $ARTIFACT_FILE"
          
          if [ ! -f "$ARTIFACT_FILE" ]; then
            echo "Missing artifact for notebook: ${notebook}" | tee -a errors.log
            echo "::error::Missing artifact for notebook: ${notebook}"
          elif grep -q "FAILED" "$ARTIFACT_FILE"; then
            echo "Execution failed for notebook: ${notebook}" | tee -a errors.log
            echo "::error::Execution failed for notebook: ${notebook}"
          else
            echo "Notebook ${notebook}: SUCCESS"
          fi
        done

        # Fail the workflow if there's anything in errors.log
        if [ -s errors.log ]; then
          echo "::error::Issues detected with one or more notebooks:"
          cat errors.log
          exit 1
        fi

        echo "All notebooks executed successfully, and all artifacts are present!"