name: (dev) Execute python notebooks

on:
  pull_request:
  workflow_dispatch:
  schedule:
    - cron: "0 0 * * 0"
  push:
    branches:
      - main

jobs:
  setup:
    runs-on: ubuntu-latest
    outputs:
      notebooks: ${{ steps.set-notebooks.outputs.notebooks }}
    steps:
    - id: checkout
      uses: actions/checkout@v3

    - id: python-setup
      name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.11'

    - id: python-dependencies
      name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install jupyter

    # Cache the installed dependencies for parallel jobs
    - name: Cache Python dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - id: set-notebooks
      name: Set notebook matrix
      run: |
        echo 'notebooks=[{"name": "integration", "path": "omics_types_integration/python/integration_notebook.ipynb"}, {"name": "over_representation", "path": "over_representation/python/overrepresentation_notebook.ipynb"}, {"name": "aggregation", "path": "proteomic_aggregation/python/proteomic_aggregation.ipynb"}, {"name": "bioscales", "path": "bioscales_biogeochemical_metadata/python/bioscales.ipynb"}, {"name": "neon", "path": "NEON_soil_metadata/python/neon_soil_metadata_visual_exploration.ipynb"}, {"name": "taxonomic", "path": "taxonomic_dist_by_soil_layer/python/taxonomic_dist_soil_layer.ipynb"}, {"name": "NOM", "path": "NOM_visualizations/python/nom_data.ipynb"}]' >> $GITHUB_OUTPUT

  execute-notebooks-dev:
    runs-on: ubuntu-latest
    needs: setup
    continue-on-error: true
    strategy:
      fail-fast: false
      matrix:
        notebook: ${{ fromJson(needs.setup.outputs.notebooks) }}
      
    steps:
    - id: checkout
      uses: actions/checkout@v3

    - id: python-setup
      name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.11'

    - id: env-vars
      name: Set up environment variables
      run: echo "Environment variables set up"
      env:
        ENV : "dev"

    - name: Restore Python dependencies cache
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - id: python-dependencies
      name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install jupyter

    - id: execute
      name: (dev) Execute ${{ matrix.notebook.name }} notebook
      run: |
        echo "Executing notebook: ${{ matrix.notebook.path }}"
        jupyter nbconvert --execute --to notebook --inplace "${{ matrix.notebook.path }}"
        
        if [ $? -ne 0 ]; then
          echo "Notebook ${{ matrix.notebook.name }} failed."
          echo "FAILED" > results-${{ matrix.notebook.name }}.txt
          exit 1
        else
          echo "SUCCESS" > results-${{ matrix.notebook.name }}.txt
        fi

    - name: Upload results
      uses: actions/upload-artifact@v4
      with:
        name: notebook-results-${{ matrix.notebook.name }}
        path: results-${{ matrix.notebook.name }}.txt

  post-check:
    runs-on: ubuntu-latest
    needs: execute-notebooks-dev
    if: always()  # Run post-check no matter what
    steps:
    - name: Gather all notebook results
      uses: actions/download-artifact@v4
      with:
        path: results/

    - name: Check notebook results
      run: |
        EXPECTED_COUNT=$(ls results/ | grep '\.txt$' | wc -l)
        ACTUAL_COUNT=$(ls results/ | grep '\.txt$' | wc -l)
        FAILED_COUNT=$(grep -l "FAILED" results/*.txt | wc -l || true)

        # Get the number of notebooks from the matrix (passed via needs)
        NOTEBOOKS_JSON='${{ needs.execute-notebooks-dev.strategy.matrix.notebook }}'
        if [ -z "$NOTEBOOKS_JSON" ]; then
          # fallback: count from files
          NOTEBOOK_COUNT=$ACTUAL_COUNT
        else
          NOTEBOOK_COUNT=$(echo "$NOTEBOOKS_JSON" | jq length)
        fi

        if [ "$ACTUAL_COUNT" -ne "$NOTEBOOK_COUNT" ]; then
          echo "Not all notebook result artifacts were found. Expected $NOTEBOOK_COUNT, found $ACTUAL_COUNT."
          exit 1
        fi

        if [ "$FAILED_COUNT" -gt 0 ]; then
          echo "At least one notebook has failed execution."
          exit 1
        else
          echo "All notebooks executed successfully!"
        fi
